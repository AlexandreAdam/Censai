{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_raytracer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHRjeXwZZ1yu9UfjBdQCIG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b27ad3552c3441d9c75e7c10038af52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac2a1cd167054239bab8180569655606",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4c5fbd279dbe4493a4abbe44f4abaf46",
              "IPY_MODEL_813d9d1872df414a8c92ef42e71bce85"
            ]
          }
        },
        "ac2a1cd167054239bab8180569655606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c5fbd279dbe4493a4abbe44f4abaf46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_fe53b1c8031d4f7f9c54a7c99139de6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.22MB of 0.22MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4425a70de647426892c7b2440f09ffa0"
          }
        },
        "813d9d1872df414a8c92ef42e71bce85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cdd7954fdebd4bac8bdbd33a3ff9bcab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ae26ac712e94ba8a6555c9507965fe2"
          }
        },
        "fe53b1c8031d4f7f9c54a7c99139de6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4425a70de647426892c7b2440f09ffa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdd7954fdebd4bac8bdbd33a3ff9bcab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ae26ac712e94ba8a6555c9507965fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreAdam/Censai/blob/eager2.4/notebooks/train_raytracer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeFvLQUwiNtM"
      },
      "source": [
        "# RayTracer\n",
        "\n",
        "Uncomment the following block to start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JY-H9B4hAA5",
        "outputId": "7422c7ee-8137-433c-8489-0cc483f04f16"
      },
      "source": [
        "!git clone https://github.com/AlexandreAdam/Censai.git\n",
        "%cd Censai\n",
        "!git checkout eager2.4\n",
        "!python setup.py install"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Censai'...\n",
            "remote: Enumerating objects: 99, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 526 (delta 38), reused 69 (delta 18), pack-reused 427\u001b[K\n",
            "Receiving objects: 100% (526/526), 13.44 MiB | 33.74 MiB/s, done.\n",
            "Resolving deltas: 100% (271/271), done.\n",
            "/content/Censai\n",
            "Branch 'eager2.4' set up to track remote branch 'eager2.4' from 'origin'.\n",
            "Switched to a new branch 'eager2.4'\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating censai.egg-info\n",
            "writing censai.egg-info/PKG-INFO\n",
            "writing dependency_links to censai.egg-info/dependency_links.txt\n",
            "writing top-level names to censai.egg-info/top_level.txt\n",
            "writing manifest file 'censai.egg-info/SOURCES.txt'\n",
            "writing manifest file 'censai.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/censai\n",
            "copying censai/physical_model.py -> build/lib/censai\n",
            "copying censai/data_generator.py -> build/lib/censai\n",
            "copying censai/utilities.py -> build/lib/censai\n",
            "copying censai/definitions.py -> build/lib/censai\n",
            "copying censai/__init__.py -> build/lib/censai\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/censai\n",
            "copying build/lib/censai/physical_model.py -> build/bdist.linux-x86_64/egg/censai\n",
            "copying build/lib/censai/data_generator.py -> build/bdist.linux-x86_64/egg/censai\n",
            "copying build/lib/censai/utilities.py -> build/bdist.linux-x86_64/egg/censai\n",
            "copying build/lib/censai/definitions.py -> build/bdist.linux-x86_64/egg/censai\n",
            "copying build/lib/censai/__init__.py -> build/bdist.linux-x86_64/egg/censai\n",
            "byte-compiling build/bdist.linux-x86_64/egg/censai/physical_model.py to physical_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/censai/data_generator.py to data_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/censai/utilities.py to utilities.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/censai/definitions.py to definitions.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/censai/__init__.py to __init__.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying censai.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying censai.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying censai.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying censai.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/censai-0.2-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing censai-0.2-py3.6.egg\n",
            "Copying censai-0.2-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding censai 0.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/censai-0.2-py3.6.egg\n",
            "Processing dependencies for censai==0.2\n",
            "Finished processing dependencies for censai==0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "A5N9uONFjFB3",
        "outputId": "d15293bd-37c9-4087-c9f5-2955104484f9"
      },
      "source": [
        "# wanb login, uncomment \n",
        "%pip install wandb -q\n",
        "import wandb\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0MB 17.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 57.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 15.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 49.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 11.1MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.19<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">easy-pine-12</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/adam-alexandre01123/censai\" target=\"_blank\">https://wandb.ai/adam-alexandre01123/censai</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/adam-alexandre01123/censai/runs/113d6h03\" target=\"_blank\">https://wandb.ai/adam-alexandre01123/censai/runs/113d6h03</a><br/>\n",
              "                Run data is saved locally in <code>/content/Censai/wandb/run-20210221_200023-113d6h03</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f057024ff98>"
            ],
            "text/html": [
              "<h1>Run(113d6h03)</h1><iframe src=\"https://wandb.ai/adam-alexandre01123/censai/runs/113d6h03\" style=\"border:none;width:100%;height:400px\"></iframe>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZDq3-7Jhayh"
      },
      "source": [
        "import tensorflow as tf\n",
        "from censai.definitions import RayTracer\n",
        "from censai.data_generator import NISGenerator\n",
        "from datetime import datetime\n",
        "import os\n",
        "# os.mkdir(Config.logdir) # run only once"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK5-gKRJl1He"
      },
      "source": [
        "def main(args):\n",
        "    if wndb:\n",
        "        config = wandb.config\n",
        "        config.learning_rate = args.lr\n",
        "        config.batch_size = args.batch_size\n",
        "        config.epochs = args.epochs\n",
        "        config.architecture=\"RayTracer UNET\"\n",
        "        config.update({\"total_items_per_batch\": args.total_items, \"validation_size\": args.validation})\n",
        "    gen = NISGenerator(args.total_items, args.batch_size)\n",
        "    gen_test = NISGenerator(args.validation, args.validation, train=False)\n",
        "    ray_tracer = RayTracer()\n",
        "    optim = tf.optimizers.Adam(lr=args.lr)\n",
        "\n",
        "    # setup tensorboard writer (nullwriter in case we do not want to sync)\n",
        "    if args.logdir.lower() != \"none\":\n",
        "        logdir = os.path.join(args.logdir, args.logname)\n",
        "        traindir = os.path.join(logdir, \"train\")\n",
        "        testdir = os.path.join(logdir, \"test\")\n",
        "        if not os.path.isdir(logdir):\n",
        "            os.mkdir(logdir)\n",
        "        if not os.path.isdir(traindir):\n",
        "            os.mkdir(traindir)\n",
        "        if not os.path.isdir(testdir):\n",
        "            os.mkdir(testdir)\n",
        "        train_writer = tf.summary.create_file_writer(traindir)\n",
        "        test_writer = tf.summary.create_file_writer(testdir)\n",
        "    else:\n",
        "        test_writer = nullwriter()\n",
        "        train_writer = nullwriter()\n",
        "\n",
        "    epoch_loss = tf.metrics.Mean()\n",
        "    step = 1\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        with train_writer.as_default():\n",
        "            for batch, (kappa, alpha) in enumerate(gen):\n",
        "                with tf.GradientTape() as tape:\n",
        "                    tape.watch(ray_tracer.trainable_variables)\n",
        "                    cost = ray_tracer.cost(kappa, alpha) # call + MSE loss function\n",
        "                    cost += tf.reduce_sum(ray_tracer.losses) # add regularizer loss\n",
        "                gradient = tape.gradient(cost, ray_tracer.trainable_variables)\n",
        "                clipped_gradient = [tf.clip_by_value(grad, -10, 10) for grad in gradient]\n",
        "                optim.apply_gradients(zip(clipped_gradient, ray_tracer.trainable_variables)) # backprop\n",
        "\n",
        "                #========== Summary and logs ==========\n",
        "                epoch_loss.update_state([cost])\n",
        "                tf.summary.scalar(\"MSE\", cost, step=step)\n",
        "                step += 1\n",
        "                \n",
        "        with test_writer.as_default():\n",
        "            for (kappa, alpha) in gen_test:\n",
        "                test_cost = ray_tracer.cost(kappa, alpha)\n",
        "            tf.summary.scalar(\"MSE\", test_cost, step=step)\n",
        "        print(f\"epoch {epoch} | train loss {epoch_loss.result().numpy():.3e} | val loss {test_cost.numpy():.3e}\")\n",
        "    return gen, gen_test, ray_tracer "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCZCxz4BIZUc"
      },
      "source": [
        "# quick hack to make a config like args of ArgumentParser\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n",
        "# setup hyperparameter and other configs\n",
        "date = datetime.now().strftime(\"%y-%m-%d_%H-%M-%S\")\n",
        "Config = AttrDict()\n",
        "Config.update({\n",
        "    #hparams\n",
        "    \"epochs\": 100,\n",
        "    \"lr\": 1e-4,\n",
        "    \"batch_size\": 50,\n",
        "    #configs\n",
        "    \"total_items\": 1000, # items per epochs\n",
        "    \"logdir\": \"logs\",\n",
        "    \"logname\": date,\n",
        "    \"validation\": 100\n",
        "})\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4b27ad3552c3441d9c75e7c10038af52",
            "ac2a1cd167054239bab8180569655606",
            "4c5fbd279dbe4493a4abbe44f4abaf46",
            "813d9d1872df414a8c92ef42e71bce85",
            "fe53b1c8031d4f7f9c54a7c99139de6e",
            "4425a70de647426892c7b2440f09ffa0",
            "cdd7954fdebd4bac8bdbd33a3ff9bcab",
            "8ae26ac712e94ba8a6555c9507965fe2"
          ]
        },
        "id": "3svWap9PJ9Kl",
        "outputId": "80b4a58b-b0ff-4a42-b4a9-3b1a9f9fa801"
      },
      "source": [
        "wndb = True\n",
        "wandb.init(project=\"censai\", entity=\"adam-alexandre01123\", sync_tensorboard=True)\n",
        "gen, gen_test, ray_tracer = main(Config)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:1dzsr4my) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 489<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b27ad3552c3441d9c75e7c10038af52",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.21MB of 0.21MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/Censai/wandb/run-20210221_203226-1dzsr4my/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/Censai/wandb/run-20210221_203226-1dzsr4my/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>train/global_step</td><td>3400</td></tr><tr><td>_timestamp</td><td>1613939997.25475</td></tr><tr><td>train/MSE</td><td>95603497369600.0</td></tr><tr><td>global_step</td><td>3401</td></tr><tr><td>_step</td><td>3400</td></tr><tr><td>test/global_step</td><td>3401</td></tr><tr><td>test/MSE</td><td>39107774382080.0</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆▆▆▆▆▆▆▆▆█████████</td></tr><tr><td>train/MSE</td><td>▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test/MSE</td><td>▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">lilac-morning-13</strong>: <a href=\"https://wandb.ai/adam-alexandre01123/censai/runs/1dzsr4my\" target=\"_blank\">https://wandb.ai/adam-alexandre01123/censai/runs/1dzsr4my</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:1dzsr4my). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.19<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">fast-frost-14</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/adam-alexandre01123/censai\" target=\"_blank\">https://wandb.ai/adam-alexandre01123/censai</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/adam-alexandre01123/censai/runs/95bakssg\" target=\"_blank\">https://wandb.ai/adam-alexandre01123/censai/runs/95bakssg</a><br/>\n",
              "                Run data is saved locally in <code>/content/Censai/wandb/run-20210221_204115-95bakssg</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call wandb.tensorboard.patch(root_logdir=\"...\") before wandb.init\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call wandb.tensorboard.patch(root_logdir=\"...\") before wandb.init\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 | train loss 5.769e+00 | val loss 5.788e+00\n",
            "epoch 2 | train loss 5.839e+00 | val loss 5.810e+00\n",
            "epoch 3 | train loss 5.899e+00 | val loss 5.789e+00\n",
            "epoch 4 | train loss 5.898e+00 | val loss 5.786e+00\n",
            "epoch 5 | train loss 5.878e+00 | val loss 5.799e+00\n",
            "epoch 6 | train loss 5.864e+00 | val loss 5.781e+00\n",
            "epoch 7 | train loss 5.852e+00 | val loss 5.787e+00\n",
            "epoch 8 | train loss 5.862e+00 | val loss 5.797e+00\n",
            "epoch 9 | train loss 5.859e+00 | val loss 5.785e+00\n",
            "epoch 10 | train loss 5.872e+00 | val loss 5.783e+00\n",
            "epoch 11 | train loss 5.868e+00 | val loss 5.817e+00\n",
            "epoch 12 | train loss 5.865e+00 | val loss 5.789e+00\n",
            "epoch 13 | train loss 5.868e+00 | val loss 5.797e+00\n",
            "epoch 14 | train loss 5.872e+00 | val loss 5.779e+00\n",
            "epoch 15 | train loss 5.866e+00 | val loss 5.793e+00\n",
            "epoch 16 | train loss 5.869e+00 | val loss 5.789e+00\n",
            "epoch 17 | train loss 5.874e+00 | val loss 5.783e+00\n",
            "epoch 18 | train loss 5.873e+00 | val loss 5.801e+00\n",
            "epoch 19 | train loss 5.872e+00 | val loss 5.789e+00\n",
            "epoch 20 | train loss 5.877e+00 | val loss 5.789e+00\n",
            "epoch 21 | train loss 5.875e+00 | val loss 5.775e+00\n",
            "epoch 22 | train loss 5.873e+00 | val loss 5.781e+00\n",
            "epoch 23 | train loss 5.870e+00 | val loss 5.790e+00\n",
            "epoch 24 | train loss 5.870e+00 | val loss 5.786e+00\n",
            "epoch 25 | train loss 5.864e+00 | val loss 5.779e+00\n",
            "epoch 26 | train loss 5.874e+00 | val loss 5.803e+00\n",
            "epoch 27 | train loss 5.869e+00 | val loss 5.796e+00\n",
            "epoch 28 | train loss 5.869e+00 | val loss 5.797e+00\n",
            "epoch 29 | train loss 5.867e+00 | val loss 5.788e+00\n",
            "epoch 30 | train loss 5.867e+00 | val loss 5.781e+00\n",
            "epoch 31 | train loss 5.863e+00 | val loss 5.790e+00\n",
            "epoch 32 | train loss 5.863e+00 | val loss 5.788e+00\n",
            "epoch 33 | train loss 5.862e+00 | val loss 5.795e+00\n",
            "epoch 34 | train loss 5.858e+00 | val loss 5.790e+00\n",
            "epoch 35 | train loss 5.853e+00 | val loss 5.792e+00\n",
            "epoch 36 | train loss 5.854e+00 | val loss 5.785e+00\n",
            "epoch 37 | train loss 5.853e+00 | val loss 5.788e+00\n",
            "epoch 38 | train loss 5.850e+00 | val loss 5.796e+00\n",
            "epoch 39 | train loss 5.853e+00 | val loss 5.786e+00\n",
            "epoch 40 | train loss 5.851e+00 | val loss 5.784e+00\n",
            "epoch 41 | train loss 5.853e+00 | val loss 5.783e+00\n",
            "epoch 42 | train loss 5.850e+00 | val loss 5.784e+00\n",
            "epoch 43 | train loss 5.850e+00 | val loss 5.784e+00\n",
            "epoch 44 | train loss 5.850e+00 | val loss 5.782e+00\n",
            "epoch 45 | train loss 5.850e+00 | val loss 5.780e+00\n",
            "epoch 46 | train loss 5.850e+00 | val loss 5.777e+00\n",
            "epoch 47 | train loss 5.849e+00 | val loss 5.787e+00\n",
            "epoch 48 | train loss 5.849e+00 | val loss 5.793e+00\n",
            "epoch 49 | train loss 5.850e+00 | val loss 5.784e+00\n",
            "epoch 50 | train loss 5.850e+00 | val loss 5.782e+00\n",
            "epoch 51 | train loss 5.849e+00 | val loss 5.784e+00\n",
            "epoch 52 | train loss 5.850e+00 | val loss 5.781e+00\n",
            "epoch 53 | train loss 5.850e+00 | val loss 5.782e+00\n",
            "epoch 54 | train loss 5.852e+00 | val loss 5.788e+00\n",
            "epoch 55 | train loss 5.852e+00 | val loss 5.794e+00\n",
            "epoch 56 | train loss 5.854e+00 | val loss 5.786e+00\n",
            "epoch 57 | train loss 5.855e+00 | val loss 5.784e+00\n",
            "epoch 58 | train loss 5.856e+00 | val loss 5.784e+00\n",
            "epoch 59 | train loss 5.858e+00 | val loss 5.784e+00\n",
            "epoch 60 | train loss 5.857e+00 | val loss 5.786e+00\n",
            "epoch 61 | train loss 5.857e+00 | val loss 5.788e+00\n",
            "epoch 62 | train loss 5.860e+00 | val loss 5.788e+00\n",
            "epoch 63 | train loss 5.861e+00 | val loss 5.787e+00\n",
            "epoch 64 | train loss 5.860e+00 | val loss 5.788e+00\n",
            "epoch 65 | train loss 5.860e+00 | val loss 5.789e+00\n",
            "epoch 66 | train loss 5.859e+00 | val loss 5.788e+00\n",
            "epoch 67 | train loss 5.860e+00 | val loss 5.786e+00\n",
            "epoch 68 | train loss 5.861e+00 | val loss 5.789e+00\n",
            "epoch 69 | train loss 5.861e+00 | val loss 5.789e+00\n",
            "epoch 70 | train loss 5.860e+00 | val loss 5.791e+00\n",
            "epoch 71 | train loss 5.858e+00 | val loss 5.789e+00\n",
            "epoch 72 | train loss 5.856e+00 | val loss 5.788e+00\n",
            "epoch 73 | train loss 5.856e+00 | val loss 5.793e+00\n",
            "epoch 74 | train loss 5.855e+00 | val loss 5.791e+00\n",
            "epoch 75 | train loss 5.855e+00 | val loss 5.788e+00\n",
            "epoch 76 | train loss 5.855e+00 | val loss 5.791e+00\n",
            "epoch 77 | train loss 5.856e+00 | val loss 5.794e+00\n",
            "epoch 78 | train loss 5.856e+00 | val loss 5.790e+00\n",
            "epoch 79 | train loss 5.857e+00 | val loss 5.787e+00\n",
            "epoch 80 | train loss 5.857e+00 | val loss 5.787e+00\n",
            "epoch 81 | train loss 5.857e+00 | val loss 5.790e+00\n",
            "epoch 82 | train loss 5.858e+00 | val loss 5.791e+00\n",
            "epoch 83 | train loss 5.859e+00 | val loss 5.789e+00\n",
            "epoch 84 | train loss 5.860e+00 | val loss 5.786e+00\n",
            "epoch 85 | train loss 5.859e+00 | val loss 5.789e+00\n",
            "epoch 86 | train loss 5.860e+00 | val loss 5.787e+00\n",
            "epoch 87 | train loss 5.860e+00 | val loss 5.785e+00\n",
            "epoch 88 | train loss 5.861e+00 | val loss 5.774e+00\n",
            "epoch 89 | train loss 5.862e+00 | val loss 5.776e+00\n",
            "epoch 90 | train loss 5.863e+00 | val loss 5.779e+00\n",
            "epoch 91 | train loss 5.864e+00 | val loss 5.781e+00\n",
            "epoch 92 | train loss 5.865e+00 | val loss 5.784e+00\n",
            "epoch 93 | train loss 5.864e+00 | val loss 5.787e+00\n",
            "epoch 94 | train loss 5.863e+00 | val loss 5.783e+00\n",
            "epoch 95 | train loss 5.863e+00 | val loss 5.782e+00\n",
            "epoch 96 | train loss 5.864e+00 | val loss 5.782e+00\n",
            "epoch 97 | train loss 5.864e+00 | val loss 5.784e+00\n",
            "epoch 98 | train loss 5.866e+00 | val loss 5.784e+00\n",
            "epoch 99 | train loss 5.866e+00 | val loss 5.785e+00\n",
            "epoch 100 | train loss 5.867e+00 | val loss 5.784e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj94RDwqKi_d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}