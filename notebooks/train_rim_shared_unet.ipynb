{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe2c7f97-06c4-425a-a03c-ddab09d6f8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from censai import PhysicalModel, RIMSharedUnet\n",
    "from censai.definitions import DTYPE\n",
    "from censai.models import SharedUnetModel\n",
    "from censai.data.lenses_tng import decode_train, decode_physical_model_info, preprocess\n",
    "from censai.utils import nullwriter, rim_residual_plot as residual_plot, plot_to_image\n",
    "import os, glob, time\n",
    "from datetime import datetime\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import random\n",
    "    \n",
    "    \n",
    "RIM_HPARAMS = [\n",
    "    \"adam\",\n",
    "    \"steps\",\n",
    "    \"kappalog\",\n",
    "    \"kappa_normalize\",\n",
    "    \"kappa_init\",\n",
    "    \"source_init\"\n",
    "]\n",
    "UNET_MODEL_HPARAMS = [\n",
    "    \"filters\",\n",
    "    \"filter_scaling\",\n",
    "    \"kernel_size\",\n",
    "    \"layers\",\n",
    "    \"block_conv_layers\",\n",
    "    \"strides\",\n",
    "    \"bottleneck_kernel_size\",\n",
    "    \"bottleneck_filters\",\n",
    "    \"resampling_kernel_size\",\n",
    "    \"input_kernel_size\",\n",
    "    \"gru_kernel_size\",\n",
    "    \"upsampling_interpolation\",\n",
    "    \"batch_norm\",\n",
    "    \"dropout_rate\",\n",
    "    \"kernel_l2_amp\",\n",
    "    \"bias_l2_amp\",\n",
    "    \"kernel_l1_amp\",\n",
    "    \"bias_l1_amp\",\n",
    "    \"activation\",\n",
    "    \"alpha\",\n",
    "    \"initializer\",\n",
    "    \"gru_architecture\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94db1c29-8e72-4b7d-a66e-f256fee49224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from censai.models.layers import UnetDecodingLayer, UnetEncodingLayer\n",
    "# # from censai.models.layers.conv_gru_component import ConvGRUBlock\n",
    "# from censai.models.utils import get_activation\n",
    "# from censai.definitions import DTYPE\n",
    "# # from censai.models.layers.conv_gru import ConvGRU\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from censai.definitions import DTYPE\n",
    "\n",
    "\n",
    "# class ConvGRU(tf.keras.layers.Layer):\n",
    "#     def __init__(self, filters=32, kernel_size=5, **kwargs):\n",
    "#         super(ConvGRU, self).__init__(dtype=DTYPE, **kwargs)\n",
    "#         self.filters = filters\n",
    "#         self.kernel_size = kernel_size\n",
    "    \n",
    "#     def build(self, input_shape):\n",
    "#         self.Wz = tf.keras.layers.Conv2D(\n",
    "#             filters=self.filters,\n",
    "#             kernel_size=self.kernel_size,\n",
    "#             strides=(1, 1),\n",
    "# #             activation='sigmoid',\n",
    "#             padding='same',\n",
    "# #             kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
    "#         )\n",
    "#         self.Uz = tf.keras.layers.Conv2D(\n",
    "#             filters=self.filters,\n",
    "#             kernel_size=self.kernel_size,\n",
    "#             strides=(1, 1),\n",
    "# #             activation='sigmoid',\n",
    "#             padding='same',\n",
    "# #             kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
    "#         )\n",
    "#         self.Bz = tf.Variable(tf.random.truncated_normal(shape=input_shape[1:], mean=0.0, stddev=0.5, dtype=DTYPE))\n",
    "        \n",
    "#         self.Wr = tf.keras.layers.Conv2D(\n",
    "#             filters=self.filters,\n",
    "#             kernel_size=self.kernel_size,\n",
    "#             strides=(1, 1),\n",
    "# #             activation='sigmoid',\n",
    "#             padding='same',\n",
    "# #             kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
    "#         )\n",
    "#         self.Ur = tf.keras.layers.Conv2D(\n",
    "#             filters=self.filters,\n",
    "#             kernel_size=self.kernel_size,\n",
    "#             strides=(1, 1),\n",
    "# #             activation='sigmoid',\n",
    "#             padding='same',\n",
    "# #             kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
    "#         )\n",
    "#         self.Br = tf.Variable(tf.random.truncated_normal(shape=input_shape[1:], mean=0.0, stddev=0.5, dtype=DTYPE))\n",
    "        \n",
    "#         self.Wh = tf.keras.layers.Conv2D(\n",
    "#             filters=self.filters,\n",
    "#             kernel_size=self.kernel_size,\n",
    "#             strides=(1, 1),\n",
    "# #             activation='sigmoid',\n",
    "#             padding='same',\n",
    "# #             kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
    "#         )\n",
    "#         self.Uh = tf.keras.layers.Conv2D(\n",
    "#             filters=self.filters,\n",
    "#             kernel_size=self.kernel_size,\n",
    "#             strides=(1, 1),\n",
    "# #             activation='sigmoid',\n",
    "#             padding='same',\n",
    "# #             kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
    "#         )\n",
    "#         self.Bh = tf.Variable(tf.random.truncated_normal(shape=input_shape[1:], mean=0.0, stddev=0.5, dtype=DTYPE))\n",
    "\n",
    "\n",
    "#     def call(self, x, ht):\n",
    "#         \"\"\"\n",
    "#         Compute the new state tensor h_{t+1}.\n",
    "#         \"\"\"\n",
    "# #         stacked_input = tf.concat([features, ht], axis=3)\n",
    "#         z = tf.nn.sigmoid(self.Wz(x) + self.Uz(ht) + self.Bz)  # Update gate vector\n",
    "#         r = tf.nn.sigmoid(self.Wr(x) + self.Ur(ht) + self.Br)    # Reset gate vector\n",
    "#         h_tilde = tf.nn.tanh(self.Wh(x) + self.Uh(r * ht) + self.Bh)  # candidate activation\n",
    "#         new_state = (1 - z) * ht + z * h_tilde\n",
    "# #         r_state = tf.multiply(r, ht)\n",
    "# #         stacked_r_state = tf.concat([features, r_state], axis=3)\n",
    "# #         tilde_h = self.candidate_activation_gate(stacked_r_state)  # candidate activation gate\n",
    "# #         new_state = tf.multiply(z, ht) + tf.multiply(1 - z, tilde_h)\n",
    "#         return new_state  # h_{t+1}\n",
    "\n",
    "\n",
    "\n",
    "# class ConvGRUBlock(tf.keras.Model):\n",
    "#     \"\"\"\n",
    "#     Abstraction for the recurrent block inside the RIM\n",
    "#     \"\"\"\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             filters,\n",
    "#             kernel_size=5,\n",
    "#             activation=tf.keras.layers.LeakyReLU()\n",
    "#     ):\n",
    "#         gru_filters = filters\n",
    "#         super(ConvGRUBlock, self).__init__()\n",
    "#         self.conv1 = tf.keras.layers.Conv2D(\n",
    "#             filters=filters,\n",
    "#             kernel_size=kernel_size,\n",
    "#             strides=1,\n",
    "#             activation=activation,\n",
    "#             padding='same')\n",
    "#         self.gru1 = ConvGRU(gru_filters, kernel_size)\n",
    "#         self.gru2 = ConvGRU(gru_filters, kernel_size)\n",
    "\n",
    "#     def call(self, inputs, state):\n",
    "#         ht_11, ht_12 = tf.split(state, 2, axis=3)\n",
    "#         gru_1_out  = self.gru1(inputs, ht_11)\n",
    "#         gru_1_outE = self.conv1(gru_1_out)\n",
    "#         gru_2_out  = self.gru2(gru_1_outE, ht_12)\n",
    "#         ht = tf.concat([gru_1_out, gru_2_out], axis=3)\n",
    "#         xt = gru_2_out\n",
    "#         return xt, ht\n",
    "\n",
    "\n",
    "# class SharedUnetModel(tf.keras.Model):\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             name=\"RIMUnetModel\",\n",
    "#             filters=32,\n",
    "#             filter_scaling=1,\n",
    "#             kernel_size=3,\n",
    "#             layers=2,                        # before bottleneck\n",
    "#             block_conv_layers=2,\n",
    "#             strides=2,\n",
    "#             bottleneck_kernel_size=None,     # use kernel_size as default\n",
    "#             bottleneck_filters=None,\n",
    "#             resampling_kernel_size=None,\n",
    "#             input_kernel_size=11,\n",
    "#             gru_kernel_size=None,\n",
    "#             batch_norm=False,\n",
    "#             upsampling_interpolation=False,  # use strided transposed convolution if false\n",
    "#             kernel_l1_amp=0.,\n",
    "#             bias_l1_amp=0.,\n",
    "#             kernel_l2_amp=0.,\n",
    "#             bias_l2_amp=0.,\n",
    "#             activation=\"leaky_relu\",\n",
    "#             alpha=0.1,                       # for leaky relu\n",
    "#             use_bias=True,\n",
    "#             trainable=True,\n",
    "#             initializer=\"glorot_uniform\",\n",
    "#     ):\n",
    "#         super(SharedUnetModel, self).__init__(name=name)\n",
    "#         self.trainable = trainable\n",
    "\n",
    "#         common_params = {\"padding\": \"same\", \"kernel_initializer\": initializer,\n",
    "#                          \"data_format\": \"channels_last\", \"use_bias\": use_bias,\n",
    "#                          \"kernel_regularizer\": tf.keras.regularizers.L1L2(l1=kernel_l1_amp, l2=kernel_l2_amp)}\n",
    "#         if use_bias:\n",
    "#             common_params.update({\"bias_regularizer\": tf.keras.regularizers.L1L2(l1=bias_l1_amp, l2=bias_l2_amp)})\n",
    "\n",
    "#         resampling_kernel_size = resampling_kernel_size if resampling_kernel_size is not None else kernel_size\n",
    "#         bottleneck_kernel_size = bottleneck_kernel_size if bottleneck_kernel_size is not None else kernel_size\n",
    "#         bottleneck_filters = bottleneck_filters if bottleneck_filters is not None else int(filter_scaling**(layers + 1) * filters)\n",
    "#         gru_kernel_size = gru_kernel_size if gru_kernel_size is not None else kernel_size\n",
    "#         activation = get_activation(activation, alpha=alpha)\n",
    "\n",
    "#         self._num_layers = layers\n",
    "#         self._strides = strides\n",
    "#         self._init_filters = filters\n",
    "#         self._filter_scaling = filter_scaling\n",
    "#         self._bottleneck_filters = bottleneck_filters\n",
    "\n",
    "#         self.encoding_layers = []\n",
    "#         self.decoding_layers = []\n",
    "#         self.gated_recurrent_blocks = []\n",
    "#         for i in range(layers):\n",
    "#             self.encoding_layers.append(\n",
    "#                 UnetEncodingLayer(\n",
    "#                     kernel_size=kernel_size,\n",
    "#                     downsampling_kernel_size=resampling_kernel_size,\n",
    "#                     filters=int(filter_scaling**(i) * filters),\n",
    "#                     conv_layers=block_conv_layers,\n",
    "#                     activation=activation,\n",
    "#                     strides=strides,\n",
    "#                     batch_norm=batch_norm,\n",
    "#                     **common_params\n",
    "#                 )\n",
    "#             )\n",
    "#             self.decoding_layers.append(\n",
    "#                 UnetDecodingLayer(\n",
    "#                     kernel_size=kernel_size,\n",
    "#                     upsampling_kernel_size=resampling_kernel_size,\n",
    "#                     filters=int(filter_scaling**(i) * filters),\n",
    "#                     conv_layers=block_conv_layers,\n",
    "#                     activation=activation,\n",
    "#                     bilinear=upsampling_interpolation,\n",
    "#                     batch_norm=batch_norm,\n",
    "#                     **common_params\n",
    "#                 )\n",
    "#             )\n",
    "#             self.gated_recurrent_blocks.append(\n",
    "#                     ConvGRUBlock(\n",
    "#                         filters=int(filter_scaling**(i) * filters),\n",
    "#                         kernel_size=gru_kernel_size,\n",
    "#                         activation=activation\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#         self.decoding_layers = self.decoding_layers[::-1]\n",
    "\n",
    "#         self.bottleneck_layer1 = tf.keras.layers.Conv2D(\n",
    "#             filters=bottleneck_filters,\n",
    "#             kernel_size=bottleneck_kernel_size,\n",
    "#             activation=activation,\n",
    "#             **common_params\n",
    "#         )\n",
    "#         self.bottleneck_layer2 = tf.keras.layers.Conv2D(\n",
    "#             filters=bottleneck_filters,\n",
    "#             kernel_size=bottleneck_kernel_size,\n",
    "#             activation=activation,\n",
    "#             **common_params\n",
    "#         )\n",
    "#         self.bottleneck_gru = ConvGRUBlock(\n",
    "#             filters=bottleneck_filters,\n",
    "#             kernel_size=bottleneck_kernel_size,\n",
    "#             activation=activation\n",
    "#         )\n",
    "\n",
    "#         self.output_layer = tf.keras.layers.Conv2D(\n",
    "#             filters=2,  # source and kappa\n",
    "#             kernel_size=(1, 1),\n",
    "#             activation=\"linear\",\n",
    "#             **common_params\n",
    "#         )        \n",
    "#         self.input_layer = tf.keras.layers.Conv2D(\n",
    "#             filters=filters,\n",
    "#             kernel_size=input_kernel_size,\n",
    "#             activation=activation,\n",
    "#             **common_params\n",
    "#         )\n",
    "\n",
    "# #     def __call__(self, source, kappa, source_grad, kappa_grad, states, lens_pred, lens_true):\n",
    "# #         return self.call(source, kappa, source_grad, kappa_grad, states, lens_pred, lens_true)\n",
    "\n",
    "# #     def call(self, source, kappa, source_grad, kappa_grad, states, lens_pred, lens_true):\n",
    "# #         delta_xt = tf.concat([source, source_grad, kappa, kappa_grad, lens_pred, lens_true], axis=-1)\n",
    "#     def __call__(self, source, kappa, source_grad, kappa_grad, states):\n",
    "#         return self.call(source, kappa, source_grad, kappa_grad, states)\n",
    "\n",
    "#     def call(self, source, kappa, source_grad, kappa_grad, states):\n",
    "#         delta_xt = tf.concat([source, source_grad, kappa, kappa_grad], axis=-1)\n",
    "#         delta_xt = self.input_layer(delta_xt)\n",
    "#         skip_connections = []\n",
    "#         new_states = []\n",
    "#         for i in range(len(self.encoding_layers)):\n",
    "#             c_i, delta_xt = self.encoding_layers[i](delta_xt)\n",
    "#             c_i, new_state = self.gated_recurrent_blocks[i](c_i, states[i])  # Pass skip connections through GRUS and update states\n",
    "#             skip_connections.append(c_i)\n",
    "#             new_states.append(new_state)\n",
    "#         skip_connections = skip_connections[::-1]\n",
    "#         delta_xt = self.bottleneck_layer1(delta_xt)\n",
    "#         delta_xt = self.bottleneck_layer2(delta_xt)\n",
    "#         delta_xt, new_state = self.bottleneck_gru(delta_xt, states[-1])\n",
    "#         new_states.append(new_state)\n",
    "#         for i in range(len(self.decoding_layers)):\n",
    "#             delta_xt = self.decoding_layers[i](delta_xt, skip_connections[i])\n",
    "#         delta_xt = self.output_layer(delta_xt)\n",
    "#         source_delta, kappa_delta = tf.split(delta_xt, 2, axis=-1)\n",
    "#         new_source = source + source_delta\n",
    "#         new_kappa = kappa + kappa_delta\n",
    "#         return new_source, new_kappa, new_states\n",
    "\n",
    "#     def init_hidden_states(self, input_pixels, batch_size, constant=0.):\n",
    "#         hidden_states = []\n",
    "#         for i in range(self._num_layers):\n",
    "#             pixels = input_pixels // self._strides**(i)\n",
    "#             filters = int(self._filter_scaling**(i) * self._init_filters)\n",
    "#             hidden_states.append(\n",
    "#                 constant * tf.ones(shape=[batch_size, pixels, pixels, 2*filters], dtype=DTYPE)\n",
    "#             )\n",
    "#         pixels = input_pixels // self._strides ** (self._num_layers)\n",
    "#         hidden_states.append(\n",
    "#             constant * tf.ones(shape=[batch_size, pixels, pixels, 2*self._bottleneck_filters], dtype=DTYPE)\n",
    "#         )\n",
    "#         return hidden_states\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9452e38d-9475-4c6e-9f97-a7ce098066d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# # from censai.models import SharedUnetModel\n",
    "# from censai.definitions import logkappa_normalization, log_10, DTYPE, logit, lrelu4p\n",
    "# from censai import PhysicalModel\n",
    "# from censai.utils import nulltape\n",
    "\n",
    "# # LAM = -0.10455389589556062\n",
    "# # LAM = -0.5369885858903738\n",
    "# # LAM = 0.42627448994956957 # applied with log_10\n",
    "# # LAM = -1.8944241461145863\n",
    "# LAM = -0.8\n",
    "# def boxcox(x):\n",
    "#     return (x**LAM - 1) / LAM\n",
    "\n",
    "# def boxcox_inverse(x):\n",
    "# #     return tf.math.exp(tf.math.log(G**(LAM-1) * LAM * x + 1) / LAM)\n",
    "#     return tf.math.exp(tf.math.log(G * LAM * x + 1) / LAM)\n",
    "\n",
    "# class RIMSharedUnet:\n",
    "#     \"\"\"\n",
    "#     Architecture has only 1 Unet. Source and kappa information are stacked along channel dimension.\n",
    "\n",
    "#     There are 2 intended structures:\n",
    "#         1. Kappa has a larger shape than Source tensor:\n",
    "#             1 - Use a half-strided convolution to upsample the output of the Unet\n",
    "#             3 - Use bilinear interpolation to upsample\n",
    "#         2. Kappa and Source have the same tensor shape -> Identity layer\n",
    "\n",
    "#     In any case, we use the Source shape for the Unet\n",
    "#     \"\"\"\n",
    "#     def __init__(\n",
    "#             self,\n",
    "#             physical_model: PhysicalModel,\n",
    "#             unet: SharedUnetModel,\n",
    "#             steps: int,\n",
    "#             adam=True,\n",
    "#             kappalog=True,\n",
    "#             kappa_normalize=False,\n",
    "#             source_link=\"relu\",\n",
    "#             beta_1=0.99,\n",
    "#             beta_2=0.999,\n",
    "#             epsilon=1e-16,\n",
    "#             kappa_init=1e-1,\n",
    "#             source_init=1e-3\n",
    "#     ):\n",
    "#         self.physical_model = physical_model\n",
    "#         self.kappa_pixels = physical_model.kappa_pixels\n",
    "#         self.source_pixels = physical_model.src_pixels\n",
    "#         self.unet = unet\n",
    "#         self.steps = steps\n",
    "#         self.adam = adam\n",
    "#         self.kappalog = kappalog\n",
    "#         self._source_link_func = source_link\n",
    "#         self.kappa_normalize = kappa_normalize\n",
    "#         self.beta_1 = beta_1\n",
    "#         self.beta_2 = beta_2\n",
    "#         self.epsilon = epsilon\n",
    "#         self._kappa_init = kappa_init\n",
    "#         self._source_init = source_init\n",
    "        \n",
    "# #         self.kappa_inverse_link = tf.keras.layers.Lambda(lambda x: boxcox(log_10(x) + 3))\n",
    "# #         self.kappa_link = tf.keras.layers.Lambda(lambda x: 10**(boxcox_inverse(x) - 3))\n",
    "\n",
    "#         if self.kappalog:\n",
    "#             if self.kappa_normalize:\n",
    "#                 self.kappa_inverse_link = tf.keras.layers.Lambda(lambda x: logkappa_normalization(log_10(x), forward=True))\n",
    "#                 self.kappa_link = tf.keras.layers.Lambda(lambda x: 10**(logkappa_normalization(x, forward=False)))\n",
    "#             else:\n",
    "#                 self.kappa_inverse_link = tf.keras.layers.Lambda(lambda x: log_10(x))\n",
    "#                 self.kappa_link = tf.keras.layers.Lambda(lambda x: 10**x)\n",
    "#         else:\n",
    "#             self.kappa_link = tf.identity\n",
    "#             self.kappa_inverse_link = tf.identity\n",
    "        \n",
    "\n",
    "#         if self._source_link_func == \"exp\":\n",
    "#             self.source_inverse_link = tf.keras.layers.Lambda(lambda x: tf.math.log(x + 1e-6))\n",
    "#             self.source_link = tf.keras.layers.Lambda(lambda x: tf.math.exp(x))\n",
    "#         elif self._source_link_func == \"identity\":\n",
    "#             self.source_inverse_link = tf.identity\n",
    "#             self.source_link = tf.identity\n",
    "#         elif self._source_link_func == \"relu\":\n",
    "#             self.source_inverse_link = tf.identity\n",
    "#             self.source_link = tf.nn.relu\n",
    "#         elif self._source_link_func == \"sigmoid\":\n",
    "#             self.source_inverse_link = logit\n",
    "#             self.source_link = tf.nn.sigmoid\n",
    "#         elif self._source_link_func == \"lrelu4p\":\n",
    "#             self.source_inverse_link = tf.identity\n",
    "#             self.source_link = lrelu4p\n",
    "#         else:\n",
    "#             raise NotImplementedError(f\"{source_link} not in ['exp', 'identity', 'relu', 'lrelu4p', 'sigmoid']\")\n",
    "\n",
    "#     def initial_states(self, batch_size):\n",
    "#         # Define initial guess in physical space, then apply inverse link function to bring them in prediction space\n",
    "#         source_init = self.source_inverse_link(tf.ones(shape=(batch_size, self.source_pixels, self.source_pixels, 1)) * self._source_init)\n",
    "#         kappa_init = self.kappa_inverse_link(tf.ones(shape=(batch_size, self.kappa_pixels, self.kappa_pixels, 1)) * self._kappa_init)\n",
    "#         states = self.unet.init_hidden_states(self.source_pixels, batch_size)\n",
    "#         return source_init, kappa_init, states\n",
    "\n",
    "#     def grad_update(self, grad1, grad2, time_step):\n",
    "#         if self.adam:\n",
    "#             if time_step == 0:  # reset mean and variance for time t=-1\n",
    "#                 self._grad_mean1 = tf.zeros_like(grad1)\n",
    "#                 self._grad_var1 = tf.zeros_like(grad1)\n",
    "#                 self._grad_mean2 = tf.zeros_like(grad2)\n",
    "#                 self._grad_var2 = tf.zeros_like(grad2)\n",
    "#             self._grad_mean1 = self. beta_1 * self._grad_mean1 + (1 - self.beta_1) * grad1\n",
    "#             self._grad_var1  = self.beta_2 * self._grad_var1 + (1 - self.beta_2) * tf.square(grad1)\n",
    "#             self._grad_mean2 = self. beta_1 * self._grad_mean2 + (1 - self.beta_1) * grad2\n",
    "#             self._grad_var2  = self.beta_2 * self._grad_var2 + (1 - self.beta_2) * tf.square(grad2)\n",
    "#             # for grad update, unbias the moments\n",
    "#             m_hat1 = self._grad_mean1 / (1 - self.beta_1**(time_step + 1))\n",
    "#             v_hat1 = self._grad_var1 / (1 - self.beta_2**(time_step + 1))\n",
    "#             m_hat2 = self._grad_mean2 / (1 - self.beta_1**(time_step + 1))\n",
    "#             v_hat2 = self._grad_var2 / (1 - self.beta_2**(time_step + 1))\n",
    "#             return m_hat1 / (tf.sqrt(v_hat1) + self.epsilon), m_hat2 / (tf.sqrt(v_hat2) + self.epsilon)\n",
    "#         else:\n",
    "#             return grad1, grad2\n",
    "\n",
    "# #     def time_step(self, source, kappa, source_grad, kappa_grad, states, lens_pred, lens_true):\n",
    "# #         source, kappa, states = self.unet(source, kappa, source_grad, kappa_grad, states, lens_pred, lens_true)\n",
    "# #         return source, kappa, states\n",
    "\n",
    "#     def time_step(self, source, kappa, source_grad, kappa_grad, states):\n",
    "#         source, kappa, states = self.unet(source, kappa, source_grad, kappa_grad, states)\n",
    "#         return source, kappa, states\n",
    "\n",
    "\n",
    "#     def __call__(self, lensed_image, outer_tape=nulltape):\n",
    "#         return self.call(lensed_image, outer_tape)\n",
    "\n",
    "#     def call(self, lensed_image, outer_tape=nulltape):\n",
    "#         \"\"\"\n",
    "#         Used in training. Return linked kappa and source maps.\n",
    "#         \"\"\"\n",
    "#         batch_size = lensed_image.shape[0]\n",
    "#         source, kappa, states = self.initial_states(batch_size)\n",
    "# #         with outer_tape.stop_recording():\n",
    "# #             y_true = tf.image.resize(lensed_image, size=(128, 128), antialias=True)\n",
    "#         source_series = tf.TensorArray(DTYPE, size=self.steps)  # equivalent to empty list and append, but using tensorflow\n",
    "#         kappa_series = tf.TensorArray(DTYPE, size=self.steps)\n",
    "#         chi_squared_series = tf.TensorArray(DTYPE, size=self.steps)\n",
    "#         for current_step in range(self.steps):\n",
    "#             with outer_tape.stop_recording():\n",
    "#                 with tf.GradientTape() as g:\n",
    "#                     g.watch(source)\n",
    "#                     g.watch(kappa)\n",
    "#                     y_pred = self.physical_model.forward(source, kappa)\n",
    "# #                     y_pred /= tf.reduce_max(y_pred, keepdims=True)\n",
    "# #                     lam = tf.reduce_sum(lensed_image * y_pred, axis=(1, 2, 3)) / tf.reduce_sum(lensed_image**2, axis=(1, 2, 3))[..., tf.newaxis, tf.newaxis, tf.newaxis]\n",
    "#                     log_likelihood = 0.5 * tf.reduce_sum((y_pred - lensed_image) ** 2 / self.physical_model.noise_rms ** 2, axis=(1, 2, 3))\n",
    "#                     cost = tf.reduce_mean(log_likelihood)\n",
    "#                 source_grad, kappa_grad = g.gradient(cost, [source, kappa])\n",
    "#                 source_grad, kappa_grad = self.grad_update(source_grad, kappa_grad, current_step)\n",
    "# #                 y_pred = tf.image.resize(y_pred, size=(128, 128), antialias=True)\n",
    "# #                 y_pred /= tf.reduce_max(y_pred, keepdims=True)\n",
    "# #             source, kappa, states = self.time_step(source, kappa, source_grad, kappa_grad, states, y_pred, y_true)\n",
    "#             source, kappa, states = self.time_step(source, kappa, source_grad, kappa_grad, states)\n",
    "#             source_series = source_series.write(index=current_step, value=source)\n",
    "#             kappa_series = kappa_series.write(index=current_step, value=kappa)\n",
    "#             chi_squared_series = chi_squared_series.write(index=current_step, value=log_likelihood)\n",
    "#         return source_series.stack(), kappa_series.stack(), chi_squared_series.stack()\n",
    "\n",
    "#     def predict(self, lensed_image):\n",
    "#         \"\"\"\n",
    "#         Used in inference. Return physical kappa and source maps.\n",
    "#         \"\"\"\n",
    "#         batch_size = lensed_image.shape[0]\n",
    "#         source, kappa, states = self.initial_states(batch_size)\n",
    "# #         y_true = tf.image.resize(lensed_image, size=(128, 128), antialias=True)\n",
    "        \n",
    "#         source_series = tf.TensorArray(DTYPE, size=self.steps)  # equivalent to empty list and append, but using tensorflow\n",
    "#         kappa_series = tf.TensorArray(DTYPE, size=self.steps)\n",
    "#         chi_squared_series = tf.TensorArray(DTYPE, size=self.steps)\n",
    "#         for current_step in range(self.steps):\n",
    "#             with tf.GradientTape() as g:\n",
    "#                 g.watch(source)\n",
    "#                 g.watch(kappa)\n",
    "#                 y_pred = self.physical_model.forward(source, kappa)\n",
    "# #                 y_pred /= tf.reduce_max(y_pred, keepdims=True)\n",
    "# #                 lam = tf.reduce_sum(lensed_image * y_pred, axis=(1, 2, 3)) / tf.reduce_sum(lensed_image**2, axis=(1, 2, 3))[..., tf.newaxis, tf.newaxis, tf.newaxis]\n",
    "#                 log_likelihood = 0.5 * tf.reduce_sum((y_pred - lensed_image) ** 2 / self.physical_model.noise_rms ** 2, axis=(1, 2, 3))\n",
    "#                 cost = tf.reduce_mean(log_likelihood)\n",
    "#             source_grad, kappa_grad = g.gradient(cost, [source, kappa])\n",
    "#             source_grad, kappa_grad = self.grad_update(source_grad, kappa_grad, current_step)\n",
    "# #             y_pred = tf.image.resize(y_pred, size=(128, 128), antialias=True)  \n",
    "# #             y_pred /= tf.reduce_max(y_pred, keepdims=True)\n",
    "\n",
    "# #             source, kappa, states = self.time_step(source, kappa, source_grad, kappa_grad, states, y_pred, y_true)  \n",
    "#             source, kappa, states = self.time_step(source, kappa, source_grad, kappa_grad, states)            \n",
    "#             source_series = source_series.write(index=current_step, value=self.source_link(source))\n",
    "#             kappa_series = kappa_series.write(index=current_step, value=self.kappa_link(kappa))\n",
    "#             chi_squared_series = chi_squared_series.write(index=current_step, value=log_likelihood)\n",
    "#         return source_series.stack(), kappa_series.stack(), chi_squared_series.stack()  # stack along 0-th dimension\n",
    "\n",
    "#     def cost_function(self, lensed_image, source, kappa, outer_tape=nulltape, reduction=True):\n",
    "#         \"\"\"\n",
    "\n",
    "#         Args:\n",
    "#             lensed_image: Batch of lensed images\n",
    "#             source: Batch of source images\n",
    "#             kappa: Batch of kappa maps\n",
    "#             reduction: Whether or not to reduce the batch dimension in computing the loss or not\n",
    "\n",
    "#         Returns: The average loss over pixels, time steps and (if reduction=True) batch size.\n",
    "\n",
    "#         \"\"\"\n",
    "#         source_series, kappa_series, chi_squared = self.call(lensed_image, outer_tape=outer_tape)\n",
    "#         source_cost = tf.reduce_sum(tf.square(source_series - self.source_inverse_link(source)), axis=0) / self.steps\n",
    "#         kappa_cost = tf.reduce_sum(tf.square(kappa_series - self.kappa_inverse_link(kappa)), axis=0) / self.steps\n",
    "#         chi = tf.reduce_sum(chi_squared, axis=0) / self.steps\n",
    "\n",
    "#         if reduction:\n",
    "#             return tf.reduce_mean(source_cost) + tf.reduce_mean(kappa_cost), tf.reduce_mean(chi)\n",
    "#         else:\n",
    "#             return tf.reduce_mean(source_cost, axis=(1, 2, 3)) + tf.reduce_mean(kappa_cost, axis=(1, 2, 3)), chi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61b52c55-c39b-4e10-97c9-b1c4e018cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    files = []\n",
    "    for dataset in args.datasets:\n",
    "        files.extend(glob.glob(os.path.join(dataset, \"*.tfrecords\")))\n",
    "    np.random.shuffle(files)\n",
    "    # Read concurrently from multiple records\n",
    "    files = tf.data.Dataset.from_tensor_slices(files)\n",
    "    dataset = files.interleave(lambda x: tf.data.TFRecordDataset(x, compression_type=args.compression_type),\n",
    "                               block_length=args.block_length, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    # Read off global parameters from first example in dataset\n",
    "    for physical_params in dataset.map(decode_physical_model_info):\n",
    "        break\n",
    "    # preprocessing\n",
    "    dataset = dataset.map(decode_train).map(preprocess)\n",
    "    if args.cache_file is not None:\n",
    "        dataset = dataset.cache(args.cache_file)\n",
    "    train_dataset = dataset.shuffle(buffer_size=args.buffer_size).take(math.floor(args.train_split * args.total_items))\\\n",
    "        .batch(args.batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    val_dataset = dataset.skip(math.floor(args.train_split * args.total_items))\\\n",
    "        .take(math.ceil((1 - args.train_split) * args.total_items)).batch(args.batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    # train_dataset = STRATEGY.experimental_distribute_dataset(train_dataset)\n",
    "    # val_dataset = STRATEGY.experimental_distribute_dataset(val_dataset)\n",
    "    if args.raytracer is not None:\n",
    "        with open(os.path.join(args.raytracer, \"ray_tracer_hparams.json\"), \"r\") as f:\n",
    "            raytracer_hparams = json.load(f)\n",
    "    # with STRATEGY.scope():  # Replicate ops accross gpus\n",
    "    if args.raytracer is not None:\n",
    "        raytracer = RayTracer(**raytracer_hparams)\n",
    "        # load last checkpoint in the checkpoint directory\n",
    "        checkpoint = tf.train.Checkpoint(net=raytracer)\n",
    "        manager = tf.train.CheckpointManager(checkpoint, directory=args.raytracer, max_to_keep=3)\n",
    "        checkpoint.restore(manager.latest_checkpoint).expect_partial()\n",
    "    else:\n",
    "        raytracer = None\n",
    "    phys = PhysicalModel(\n",
    "        pixels=physical_params[\"pixels\"].numpy(),\n",
    "        kappa_pixels=physical_params[\"kappa pixels\"].numpy(),\n",
    "        src_pixels=physical_params[\"src pixels\"].numpy(),\n",
    "        image_fov=physical_params[\"image fov\"].numpy(),\n",
    "        kappa_fov=physical_params[\"kappa fov\"].numpy(),\n",
    "        src_fov=physical_params[\"source fov\"].numpy(),\n",
    "        method=args.forward_method,\n",
    "        noise_rms=physical_params[\"noise rms\"].numpy(),\n",
    "        raytracer=raytracer,\n",
    "        psf_sigma=physical_params[\"psf sigma\"].numpy()\n",
    "    )\n",
    "\n",
    "    unet = SharedUnetModel(\n",
    "        filters=args.filters,\n",
    "        filter_scaling=args.filter_scaling,\n",
    "        kernel_size=args.kernel_size,\n",
    "        layers=args.layers,\n",
    "        block_conv_layers=args.block_conv_layers,\n",
    "        strides=args.strides,\n",
    "        bottleneck_kernel_size=args.bottleneck_kernel_size,\n",
    "        bottleneck_filters=args.bottleneck_filters,\n",
    "        resampling_kernel_size=args.resampling_kernel_size,\n",
    "        input_kernel_size=args.input_kernel_size,\n",
    "        gru_kernel_size=args.gru_kernel_size,\n",
    "        upsampling_interpolation=args.upsampling_interpolation,\n",
    "        kernel_l2_amp=args.kernel_l2_amp,\n",
    "        bias_l2_amp=args.bias_l2_amp,\n",
    "        kernel_l1_amp=args.kernel_l1_amp,\n",
    "        bias_l1_amp=args.bias_l1_amp,\n",
    "        activation=args.activation,\n",
    "        alpha=args.alpha,\n",
    "        initializer=args.initializer,\n",
    "        batch_norm=args.batch_norm,\n",
    "        dropout_rate=args.dropout_rate\n",
    "    )\n",
    "    rim = RIMSharedUnet(\n",
    "        physical_model=phys,\n",
    "        unet=unet,\n",
    "        steps=args.steps,\n",
    "        adam=args.adam,\n",
    "        kappalog=args.kappalog,\n",
    "        source_link=args.source_link,\n",
    "        kappa_normalize=args.kappa_normalize,\n",
    "        kappa_init=args.kappa_init,\n",
    "        source_init=args.source_init\n",
    "    )\n",
    "    learning_rate_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=args.initial_learning_rate,\n",
    "        decay_rate=args.decay_rate,\n",
    "        decay_steps=args.decay_steps,\n",
    "        staircase=args.staircase\n",
    "    )\n",
    "    optim = tf.keras.optimizers.deserialize(\n",
    "        {\n",
    "            \"class_name\": args.optimizer,\n",
    "            'config': {\"learning_rate\": learning_rate_schedule}\n",
    "        }\n",
    "    )\n",
    "    # weights for time steps in the loss function\n",
    "    if args.time_weights == \"uniform\":\n",
    "        wt = tf.ones(shape=(args.steps), dtype=DTYPE) / args.steps\n",
    "    elif args.time_weights == \"linear\":\n",
    "        wt = 2 * (tf.range(args.steps, dtype=DTYPE) + 1) / args.steps / (args.steps + 1)\n",
    "    elif args.time_weights == \"quadratic\":\n",
    "        wt = 6 * (tf.range(args.steps, dtype=DTYPE) + 1)**2 / args.steps / (args.steps + 1) / (2 * args.steps + 1)\n",
    "    else:\n",
    "        raise ValueError(\"time_weights must be in ['uniform', 'linear', 'quadratic']\")\n",
    "    wt = wt[..., tf.newaxis]  # [steps, batch]\n",
    "    # ==== Take care of where to write logs and stuff =================================================================\n",
    "    if args.model_id.lower() != \"none\":\n",
    "        logname = args.model_id + \"_\" + args.logname if args.logname is not None else args.model_id\n",
    "        model_id = args.model_id\n",
    "    elif args.logname is not None:\n",
    "        logname = args.logname\n",
    "        model_id = logname\n",
    "    else:\n",
    "        logname = args.logname_prefixe + \"_\" + datetime.now().strftime(\"%y-%m-%d_%H-%M-%S\")\n",
    "        model_id = logname\n",
    "    if args.logdir.lower() != \"none\":\n",
    "        logdir = os.path.join(args.logdir, logname)\n",
    "        if not os.path.isdir(logdir):\n",
    "            os.mkdir(logdir)\n",
    "        writer = tf.summary.create_file_writer(logdir)\n",
    "    else:\n",
    "        writer = nullwriter()\n",
    "    # ===== Make sure directory and checkpoint manager are created to save model ===================================\n",
    "    if args.model_dir.lower() != \"none\":\n",
    "        checkpoints_dir = os.path.join(args.model_dir, logname)\n",
    "        old_checkpoints_dir = os.path.join(args.model_dir, model_id)  # in case they differ we load model from a different directory\n",
    "        if not os.path.isdir(checkpoints_dir):\n",
    "            os.mkdir(checkpoints_dir)\n",
    "            with open(os.path.join(checkpoints_dir, \"script_params.json\"), \"w\") as f:\n",
    "                json.dump(vars(args), f, indent=4)\n",
    "            with open(os.path.join(checkpoints_dir, \"unet_hparams.json\"), \"w\") as f:\n",
    "                hparams_dict = {key: vars(args)[key] for key in UNET_MODEL_HPARAMS}\n",
    "                json.dump(hparams_dict, f, indent=4)\n",
    "            with open(os.path.join(checkpoints_dir, \"rim_hparams.json\"), \"w\") as f:\n",
    "                hparams_dict = {key: vars(args)[key] for key in RIM_HPARAMS}\n",
    "                json.dump(hparams_dict, f, indent=4)\n",
    "        ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optim, net=rim.unet)\n",
    "        checkpoint_manager = tf.train.CheckpointManager(ckpt, old_checkpoints_dir, max_to_keep=args.max_to_keep)\n",
    "        save_checkpoint = True\n",
    "        # ======= Load model if model_id is provided ===============================================================\n",
    "        if args.model_id.lower() != \"none\":\n",
    "            checkpoint_manager.checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "        if old_checkpoints_dir != checkpoints_dir:  # save progress in another directory.\n",
    "            checkpoint_manager = tf.train.CheckpointManager(ckpt, checkpoints_dir, max_to_keep=args.max_to_keep)\n",
    "    else:\n",
    "        save_checkpoint = False\n",
    "    # =================================================================================================================\n",
    "\n",
    "    def train_step(X, source, kappa):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(rim.unet.trainable_variables)\n",
    "            source_series, kappa_series, chi_squared = rim.call(X, outer_tape=tape)\n",
    "            # mean over image residuals\n",
    "            source_cost = tf.reduce_mean(tf.square(source_series - rim.source_inverse_link(source)), axis=(2, 3, 4))\n",
    "            kappa_cost = tf.reduce_mean(tf.square(kappa_series - rim.kappa_inverse_link(kappa)), axis=(2, 3, 4))\n",
    "            # weighted mean over time steps\n",
    "            source_cost = tf.reduce_sum(wt * source_cost, axis=0)\n",
    "            kappa_cost = tf.reduce_sum(wt * kappa_cost, axis=0)\n",
    "            # final cost is mean over global batch size\n",
    "            cost = tf.reduce_sum(kappa_cost + source_cost) / args.batch_size\n",
    "        gradient = tape.gradient(cost, rim.unet.trainable_variables)\n",
    "        if args.clipping:\n",
    "            gradient = [tf.clip_by_value(grad, -10, 10) for grad in gradient]\n",
    "        optim.apply_gradients(zip(gradient, rim.unet.trainable_variables))\n",
    "        chi_squared = tf.reduce_sum(chi_squared[-1]) / args.batch_size # take chi squared of converged prediction\n",
    "        source_cost = tf.reduce_sum(source_cost) / args.batch_size\n",
    "        kappa_cost = tf.reduce_sum(kappa_cost) / args.batch_size\n",
    "        return cost, chi_squared, source_cost, kappa_cost\n",
    "\n",
    "    # @tf.function\n",
    "    # def distributed_train_step(dist_inputs):\n",
    "    #     per_replica_losses, per_replica_chi_squared, per_replica_source_cost, per_replica_kappa_cost = STRATEGY.run(train_step, args=(dist_inputs,))\n",
    "    #     # Replica losses are aggregated by summing them\n",
    "    #     global_loss = STRATEGY.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "    #     global_chi_squared = STRATEGY.reduce(tf.distribute.ReduceOp.SUM, per_replica_chi_squared, axis=None)\n",
    "    #     global_source_cost = STRATEGY.reduce(tf.distribute.ReduceOp.SUM, per_replica_source_cost, axis=None)\n",
    "    #     global_kappa_cost = STRATEGY.reduce(tf.distribute.ReduceOp.SUM, per_replica_kappa_cost, axis=None)\n",
    "    #     return global_loss, global_chi_squared, global_source_cost, global_kappa_cost\n",
    "\n",
    "    def test_step(X, source, kappa):\n",
    "        source_series, kappa_series, chi_squared = rim.call(X)\n",
    "        # mean over image residuals\n",
    "        source_cost = tf.reduce_mean(tf.square(source_series - rim.source_inverse_link(source)), axis=(2, 3, 4))\n",
    "        kappa_cost = tf.reduce_mean(tf.square(kappa_series - rim.kappa_inverse_link(kappa)), axis=(2, 3, 4))\n",
    "        # weighted mean over time steps\n",
    "        source_cost = tf.reduce_sum(wt * source_cost, axis=0)\n",
    "        kappa_cost = tf.reduce_sum(wt * kappa_cost, axis=0)\n",
    "        # final cost is mean over global batch size\n",
    "        cost = tf.reduce_sum(kappa_cost + source_cost) / args.batch_size\n",
    "        chi_squared = tf.reduce_sum(chi_squared[-1]) / args.batch_size\n",
    "        source_cost = tf.reduce_sum(source_cost) / args.batch_size\n",
    "        kappa_cost = tf.reduce_sum(kappa_cost) / args.batch_size\n",
    "        return cost, chi_squared, source_cost, kappa_cost\n",
    "\n",
    "    # @tf.function\n",
    "    # def distributed_test_step(dist_inputs):\n",
    "    #     per_replica_losses, per_replica_chi_squared, per_replica_source_cost, per_replica_kappa_cost = STRATEGY.run(test_step, args=(dist_inputs,))\n",
    "    #     # Replica losses are aggregated by summing them\n",
    "    #     global_loss = STRATEGY.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "    #     global_chi_squared = STRATEGY.reduce(tf.distribute.ReduceOp.SUM, per_replica_chi_squared, axis=None)\n",
    "    #     global_source_cost = STRATEGY.reduce(tf.distribute.ReduceOp.SUM, per_replica_source_cost, axis=None)\n",
    "    #     global_kappa_cost = STRATEGY.reduce(tf.distribute.ReduceOp.SUM, per_replica_kappa_cost, axis=None)\n",
    "    #     return global_loss, global_chi_squared, global_source_cost, global_kappa_cost\n",
    "\n",
    "    # ====== Training loop ============================================================================================\n",
    "    epoch_loss = tf.metrics.Mean()\n",
    "    time_per_step = tf.metrics.Mean()\n",
    "    val_loss = tf.metrics.Mean()\n",
    "    epoch_chi_squared = tf.metrics.Mean()\n",
    "    epoch_source_loss = tf.metrics.Mean()\n",
    "    epoch_kappa_loss = tf.metrics.Mean()\n",
    "    val_chi_squared = tf.metrics.Mean()\n",
    "    val_source_loss = tf.metrics.Mean()\n",
    "    val_kappa_loss = tf.metrics.Mean()\n",
    "    history = {  # recorded at the end of an epoch only\n",
    "        \"train_cost\": [],\n",
    "        \"train_chi_squared\": [],\n",
    "        \"train_source_cost\": [],\n",
    "        \"train_kappa_cost\": [],\n",
    "        \"val_cost\": [],\n",
    "        \"val_chi_squared\": [],\n",
    "        \"val_source_cost\": [],\n",
    "        \"val_kappa_cost\": [],\n",
    "        \"learning_rate\": [],\n",
    "        \"time_per_step\": [],\n",
    "        \"step\": [],\n",
    "        \"wall_time\": []\n",
    "    }\n",
    "    best_loss = np.inf\n",
    "    patience = args.patience\n",
    "    step = 0\n",
    "    global_start = time.time()\n",
    "    estimated_time_for_epoch = 0\n",
    "    out_of_time = False\n",
    "    lastest_checkpoint = 1\n",
    "    for epoch in range(args.epochs):\n",
    "        if (time.time() - global_start) > args.max_time*3600 - estimated_time_for_epoch:\n",
    "            break\n",
    "        epoch_start = time.time()\n",
    "        epoch_loss.reset_states()\n",
    "        epoch_chi_squared.reset_states()\n",
    "        epoch_source_loss.reset_states()\n",
    "        epoch_kappa_loss.reset_states()\n",
    "        time_per_step.reset_states()\n",
    "        with writer.as_default():\n",
    "            for batch, (X, source, kappa) in enumerate(train_dataset):\n",
    "                start = time.time()\n",
    "                cost, chi_squared, source_cost, kappa_cost = train_step(X, source, kappa)\n",
    "        # ========== Summary and logs ==================================================================================\n",
    "                _time = time.time() - start\n",
    "                time_per_step.update_state([_time])\n",
    "                epoch_loss.update_state([cost])\n",
    "                epoch_chi_squared.update_state([chi_squared])\n",
    "                epoch_source_loss.update_state([source_cost])\n",
    "                epoch_kappa_loss.update_state([kappa_cost])\n",
    "                step += 1\n",
    "            # last batch we make a summary of residuals\n",
    "            if args.n_residuals > 0:\n",
    "                source_pred, kappa_pred, chi_squared = rim.predict(X)\n",
    "                lens_pred = phys.forward(source_pred[-1], kappa_pred[-1])\n",
    "                lam = phys.lagrange_multiplier(y_true=X, y_pred=lens_pred)\n",
    "            for res_idx in range(min(args.n_residuals, args.batch_size)):\n",
    "                try:\n",
    "                    tf.summary.image(f\"Residuals {res_idx}\",\n",
    "                                     plot_to_image(\n",
    "                                         residual_plot(\n",
    "                                             lam[res_idx]*X[res_idx],\n",
    "                                             source[res_idx],\n",
    "                                             kappa[res_idx],\n",
    "                                             lens_pred[res_idx],\n",
    "                                             source_pred[-1][res_idx],\n",
    "                                             kappa_pred[-1][res_idx],\n",
    "                                             chi_squared[-1][res_idx]\n",
    "                                         )), step=step)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "            # ========== Validation set ===================\n",
    "            val_loss.reset_states()\n",
    "            val_chi_squared.reset_states()\n",
    "            val_source_loss.reset_states()\n",
    "            val_kappa_loss.reset_states()\n",
    "            for X, source, kappa in val_dataset:\n",
    "                cost, chi_squared, source_cost, kappa_cost = test_step(X, source, kappa)\n",
    "                val_loss.update_state([cost])\n",
    "                val_chi_squared.update_state([chi_squared])\n",
    "                val_source_loss.update_state([source_cost])\n",
    "                val_kappa_loss.update_state([kappa_cost])\n",
    "\n",
    "            if args.n_residuals > 0 and math.ceil((1 - args.train_split) * args.total_items) > 0:  # validation set not empty set not empty\n",
    "                source_pred, kappa_pred, chi_squared = rim.predict(X)\n",
    "                lens_pred = phys.forward(source_pred[-1], kappa_pred[-1])\n",
    "                lam = phys.lagrange_multiplier(y_true=X, y_pred=lens_pred)\n",
    "            for res_idx in range(min(args.n_residuals, args.batch_size, math.ceil((1 - args.train_split) * args.total_items))):\n",
    "                try:\n",
    "                    tf.summary.image(f\"Val Residuals {res_idx}\",\n",
    "                                     plot_to_image(\n",
    "                                         residual_plot(\n",
    "                                             lam[res_idx]*X[res_idx],  # rescale intensity like it is done in the likelihood\n",
    "                                             source[res_idx],\n",
    "                                             kappa[res_idx],\n",
    "                                             lens_pred[res_idx],\n",
    "                                             source_pred[-1][res_idx],\n",
    "                                             kappa_pred[-1][res_idx],\n",
    "                                             chi_squared[-1][res_idx]\n",
    "                                         )), step=step)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            val_cost = val_loss.result().numpy()\n",
    "            train_cost = epoch_loss.result().numpy()\n",
    "            val_chi_sq = val_chi_squared.result().numpy()\n",
    "            train_chi_sq = epoch_chi_squared.result().numpy()\n",
    "            val_kappa_cost = val_kappa_loss.result().numpy()\n",
    "            train_kappa_cost = epoch_kappa_loss.result().numpy()\n",
    "            val_source_cost = val_source_loss.result().numpy()\n",
    "            train_source_cost = epoch_source_loss.result().numpy()\n",
    "            tf.summary.scalar(\"Time per step\", time_per_step.result(), step=step)\n",
    "            tf.summary.scalar(\"Chi Squared\", train_chi_sq, step=step)\n",
    "            tf.summary.scalar(\"Kappa cost\", train_kappa_cost, step=step)\n",
    "            tf.summary.scalar(\"Val Kappa cost\", val_kappa_cost, step=step)\n",
    "            tf.summary.scalar(\"Source cost\", train_source_cost, step=step)\n",
    "            tf.summary.scalar(\"Val Source cost\", val_source_cost, step=step)\n",
    "            tf.summary.scalar(\"MSE\", train_cost, step=step)\n",
    "            tf.summary.scalar(\"Val MSE\", val_cost, step=step)\n",
    "            tf.summary.scalar(\"Learning Rate\", optim.lr(step), step=step)\n",
    "            tf.summary.scalar(\"Val Chi Squared\", val_chi_sq, step=step)\n",
    "        print(f\"epoch {epoch} | train loss {train_cost:.3e} | val loss {val_cost:.3e} \"\n",
    "              f\"| lr {optim.lr(step).numpy():.2e} | time per step {time_per_step.result().numpy():.2e} s\"\n",
    "              f\"| kappa cost {train_kappa_cost:.2e} | source cost {train_source_cost:.2e} | chi sq {train_chi_sq:.2e}\")\n",
    "        history[\"train_cost\"].append(train_cost)\n",
    "        history[\"val_cost\"].append(val_cost)\n",
    "        history[\"learning_rate\"].append(optim.lr(step).numpy())\n",
    "        history[\"train_chi_squared\"].append(train_chi_sq)\n",
    "        history[\"val_chi_squared\"].append(val_chi_sq)\n",
    "        history[\"time_per_step\"].append(time_per_step.result().numpy())\n",
    "        history[\"train_kappa_cost\"].append(train_kappa_cost)\n",
    "        history[\"train_source_cost\"].append(train_source_cost)\n",
    "        history[\"val_kappa_cost\"].append(val_kappa_cost)\n",
    "        history[\"val_source_cost\"].append(val_source_cost)\n",
    "        history[\"step\"].append(step)\n",
    "        history[\"wall_time\"].append(time.time() - global_start)\n",
    "\n",
    "        cost = train_cost if args.track_train else val_cost\n",
    "        if np.isnan(cost):\n",
    "            print(\"Training broke the Universe\")\n",
    "            break\n",
    "        if cost < (1 - args.tolerance) * best_loss:\n",
    "            best_loss = cost\n",
    "            patience = args.patience\n",
    "        else:\n",
    "            patience -= 1\n",
    "        if (time.time() - global_start) > args.max_time * 3600:\n",
    "            out_of_time = True\n",
    "        if save_checkpoint:\n",
    "            checkpoint_manager.checkpoint.step.assign_add(1) # a bit of a hack\n",
    "            if epoch % args.checkpoints == 0 or patience == 0 or epoch == args.epochs - 1 or out_of_time:\n",
    "                with open(os.path.join(checkpoints_dir, \"score_sheet.txt\"), mode=\"a\") as f:\n",
    "                    np.savetxt(f, np.array([[lastest_checkpoint, cost]]))\n",
    "                lastest_checkpoint += 1\n",
    "                checkpoint_manager.save()\n",
    "                print(\"Saved checkpoint for step {}: {}\".format(int(checkpoint_manager.checkpoint.step), checkpoint_manager.latest_checkpoint))\n",
    "        if patience == 0:\n",
    "            print(\"Reached patience\")\n",
    "            break\n",
    "        if out_of_time:\n",
    "            break\n",
    "        if epoch > 0:  # First epoch is always very slow and not a good estimate of an epoch time.\n",
    "            estimated_time_for_epoch = time.time() - epoch_start\n",
    "    print(f\"Finished training after {(time.time() - global_start)/3600:.3f} hours.\")\n",
    "    return rim, phys, train_dataset, val_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5d9e6ec-4f29-491a-9755-9fb1d97d3571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--json_override'], dest='json_override', nargs='+', const=None, default=None, type=None, choices=None, help='A json filepath that will override every command line parameters. Useful for reproducibility', metavar=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "import json\n",
    "parser = ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--model_id\",               default=\"None\",                 help=\"Start from this model id checkpoint. None means start from scratch\")\n",
    "parser.add_argument(\"--datasets\",               required=True,  nargs=\"+\",      help=\"Path to directories that contains tfrecords of dataset. Can be multiple inputs (space separated)\")\n",
    "parser.add_argument(\"--compression_type\",       default=None,                   help=\"Compression type used to write data. Default assumes no compression.\")\n",
    "\n",
    "# RIM hyperparameters\n",
    "parser.add_argument(\"--steps\",              default=16,     type=int,       help=\"Number of time steps of RIM\")\n",
    "parser.add_argument(\"--adam\",               action=\"store_true\",            help=\"ADAM update for the log-likelihood gradient.\")\n",
    "parser.add_argument(\"--kappalog\",           action=\"store_true\")\n",
    "parser.add_argument(\"--kappa_normalize\",    action=\"store_true\")\n",
    "parser.add_argument(\"--source_link\",        default=\"identity\",             help=\"One of 'exp', 'source', 'relu' or 'identity' (default).\")\n",
    "parser.add_argument(\"--kappa_init\",         default=1e-1,   type=float,     help=\"Initial value of kappa for RIM\")\n",
    "parser.add_argument(\"--source_init\",        default=1e-3,   type=float,     help=\"Initial value of source for RIM\")\n",
    "\n",
    "# Shared Unet params\n",
    "parser.add_argument(\"--filters\",                                    default=32,     type=int)\n",
    "parser.add_argument(\"--filter_scaling\",                             default=1,      type=float)\n",
    "parser.add_argument(\"--kernel_size\",                                default=3,      type=int)\n",
    "parser.add_argument(\"--layers\",                                     default=2,      type=int)\n",
    "parser.add_argument(\"--block_conv_layers\",                          default=2,      type=int)\n",
    "parser.add_argument(\"--strides\",                                    default=2,      type=int)\n",
    "parser.add_argument(\"--bottleneck_kernel_size\",                     default=None,   type=int)\n",
    "parser.add_argument(\"--bottleneck_filters\",                         default=None,   type=int)\n",
    "parser.add_argument(\"--resampling_kernel_size\",                     default=None,   type=int)\n",
    "parser.add_argument(\"--input_kernel_size\",                          default=11,     type=int)\n",
    "parser.add_argument(\"--gru_kernel_size\",                            default=None,   type=int)\n",
    "parser.add_argument(\"--upsampling_interpolation\",                   action=\"store_true\")\n",
    "parser.add_argument(\"--batch_norm\",                                 action=\"store_true\")\n",
    "parser.add_argument(\"--dropout_rate\",                               default=None,   type=float)\n",
    "parser.add_argument(\"--kernel_l2_amp\",                              default=0,      type=float)\n",
    "parser.add_argument(\"--bias_l2_amp\",                                default=0,      type=float)\n",
    "parser.add_argument(\"--kernel_l1_amp\",                              default=0,      type=float)\n",
    "parser.add_argument(\"--bias_l1_amp\",                                default=0,      type=float)\n",
    "parser.add_argument(\"--activation\",                                 default=\"leaky_relu\")\n",
    "parser.add_argument(\"--alpha\",                                      default=0.1,    type=float)\n",
    "parser.add_argument(\"--initializer\",                                default=\"glorot_normal\")\n",
    "parser.add_argument(\"--gru_architecture\",                           default=\"concat\",   help=\"'concat': architecture of Laurence. 'plus': original RNN architecture\")\n",
    "\n",
    "\n",
    "# Physical model hyperparameter\n",
    "parser.add_argument(\"--forward_method\",         default=\"conv2d\",               help=\"One of ['conv2d', 'fft', 'unet']. If the option 'unet' is chosen, the parameter \"\n",
    "                                                                                     \"'--raytracer' must be provided and point to model checkpoint directory.\")\n",
    "parser.add_argument(\"--raytracer\",              default=None,                   help=\"Path to raytracer checkpoint dir if method 'unet' is used.\")\n",
    "\n",
    "# Training set params\n",
    "parser.add_argument(\"-b\", \"--batch_size\",       default=1,      type=int,       help=\"Number of images in a batch. \")\n",
    "parser.add_argument(\"--train_split\",            default=0.8,    type=float,     help=\"Fraction of the training set.\")\n",
    "parser.add_argument(\"--total_items\",            required=True,  type=int,       help=\"Total images in an epoch.\")\n",
    "# ... for tfrecord dataset\n",
    "parser.add_argument(\"--cache_file\",             default=None,                   help=\"Path to cache file, useful when training on server. Use ${SLURM_TMPDIR}/cache\")\n",
    "parser.add_argument(\"--block_length\",           default=1,      type=int,       help=\"Number of example to read from each files at a given moment.\")\n",
    "parser.add_argument(\"--buffer_size\",            default=1000,   type=int,       help=\"Buffer size for shuffling at each epoch.\")\n",
    "\n",
    "# Optimization params\n",
    "parser.add_argument(\"-e\", \"--epochs\",           default=10,     type=int,       help=\"Number of epochs for training.\")\n",
    "parser.add_argument(\"--optimizer\",              default=\"Adam\",                 help=\"Class name of the optimizer (e.g. 'Adam' or 'Adamax')\")\n",
    "parser.add_argument(\"--initial_learning_rate\",  default=1e-3,   type=float,     help=\"Initial learning rate.\")\n",
    "parser.add_argument(\"--decay_rate\",             default=1.,     type=float,     help=\"Exponential decay rate of learning rate (1=no decay).\")\n",
    "parser.add_argument(\"--decay_steps\",            default=1000,   type=int,       help=\"Decay steps of exponential decay of the learning rate.\")\n",
    "parser.add_argument(\"--staircase\",              action=\"store_true\",            help=\"Learning rate schedule only change after decay steps if enabled.\")\n",
    "parser.add_argument(\"--clipping\",               action=\"store_true\",            help=\"Clip backprop gradients between -10 and 10.\")\n",
    "parser.add_argument(\"--patience\",               default=np.inf, type=int,       help=\"Number of step at which training is stopped if no improvement is recorder.\")\n",
    "parser.add_argument(\"--tolerance\",              default=0,      type=float,     help=\"Current score <= (1 - tolerance) * best score => reset patience, else reduce patience.\")\n",
    "parser.add_argument(\"--track_train\",            action=\"store_true\",            help=\"Track training metric instead of validation metric, in case we want to overfit\")\n",
    "parser.add_argument(\"--max_time\",               default=np.inf, type=float,     help=\"Time allowed for the training, in hours.\")\n",
    "parser.add_argument(\"--time_weights\",           default=\"uniform\",              help=\"uniform: w_t=1 for all t, linear: w_t~t, quadratic: w_t~t^2\")\n",
    "\n",
    "# logs\n",
    "parser.add_argument(\"--logdir\",                  default=\"None\",                help=\"Path of logs directory. Default if None, no logs recorded.\")\n",
    "parser.add_argument(\"--logname\",                 default=None,                  help=\"Overwrite name of the log with this argument\")\n",
    "parser.add_argument(\"--logname_prefixe\",         default=\"RIMUnet512\",          help=\"If name of the log is not provided, this prefix is prepended to the date\")\n",
    "parser.add_argument(\"--model_dir\",               default=\"None\",                help=\"Path to the directory where to save models checkpoints.\")\n",
    "parser.add_argument(\"--checkpoints\",             default=10,    type=int,       help=\"Save a checkpoint of the models each {%} iteration.\")\n",
    "parser.add_argument(\"--max_to_keep\",             default=3,     type=int,       help=\"Max model checkpoint to keep.\")\n",
    "parser.add_argument(\"--n_residuals\",             default=1,     type=int,       help=\"Number of residual plots to save. Add overhead at the end of an epoch only.\")\n",
    "\n",
    "# Reproducibility params\n",
    "parser.add_argument(\"--seed\",                   default=None,   type=int,       help=\"Random seed for numpy and tensorflow.\")\n",
    "parser.add_argument(\"--json_override\",          default=None,    nargs=\"+\",     help=\"A json filepath that will override every command line parameters. \"\n",
    "                                                                             \"Useful for reproducibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44438a45-448e-4a1e-8ddd-413b63b8cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['']\n",
    "args = parser.parse_args(\n",
    "  f\"--datasets {os.getenv('CENSAI_PATH')}/data/lenses512_hk128_TNG100_10k_verydiffuse \"\\\n",
    "  f\"--compression_type=GZIP \"\\\n",
    "  f\"--forward_method=fft \"\\\n",
    "  f\"--optimizer=ADAMAX \"\\\n",
    "  f\"--epochs=200 \"\\\n",
    "  f\"--max_time=1 \"\\\n",
    "  f\"--initial_learning_rate=5e-4 \"\\\n",
    "  f\"--decay_rate=0.5 \"\\\n",
    "  f\"--decay_steps=10 \"\\\n",
    "  f\"--staircase \"\\\n",
    "  f\"--clipping \"\\\n",
    "  f\"--patience=20 \"\\\n",
    "#   f\"--tolerance=0.01 \"\\\n",
    "  f\"--batch_size=10 \"\\\n",
    "  f\"--train_split=1 \"\\\n",
    "  f\"--total_items=100 \"\\\n",
    "  f\"--block_length=1 \"\\\n",
    "  f\"--buffer_size=100 \"\\\n",
    "  f\"--steps=15 \"\\\n",
    "  f\"--time_weights=quadratic \"\\\n",
    "  f\"--adam \"\\\n",
    "  f\"--kappalog \"\\\n",
    "  f\"--source_link=lrelu4p \"\\\n",
    "  f\"--filters=8 \"\\\n",
    "  f\"--filter_scaling=2 \"\\\n",
    "  f\"--kernel_size=3 \"\\\n",
    "  f\"--input_kernel_size=3 \"\\\n",
    "  f\"--layers=3 \"\\\n",
    "  f\"--block_conv_layers=1 \"\\\n",
    "#   f\"--resampling_kernel_size=3 \"\\\n",
    "#   f\"--gru_kernel_size=3 \"\\\n",
    "#   f\"--batch_norm \"\\\n",
    "#   f\"--dropout=0.1 \"\\\n",
    "#   f\"--upsampling_interpolation \"\\\n",
    "#   f\"--kernel_l2_amp=1e-4 \"\\\n",
    "#   f\"--bias_l2_amp=1e-4 \"\\\n",
    "  f\"--kernel_l1_amp=1e-3 \"\\\n",
    "  f\"--bias_l1_amp=1e-3 \"\\\n",
    "  f\"--activation=tanh \"\\\n",
    "#   f\"--alpha=0.3 \"\\\n",
    "  f\"--cache_file={os.getenv('SLURM_TMPDIR')}/cache \"\\\n",
    "  f\"--logdir={os.getenv('HOME')}/scratch/Censai/logs \"\\\n",
    "  f\"--logname_prefixe=RIMSU512_k128_hTNG_interactive \"\\\n",
    "  f\"--track_train \"\\\n",
    "  f\"--model_dir={os.getenv('HOME')}/scratch/Censai/models \"\\\n",
    "  f\"--checkpoints=5 \"\\\n",
    "  f\"--max_to_keep=3 \"\\\n",
    "  f\"--seed=42 \"\\\n",
    "  f\"--n_residuals=0 \".split()\n",
    "#   f\"--json_override {os.getenv('CENSAI_PATH')}/models/{model_id}/unet_hparams.json {os.getenv('CENSAI_PATH')}/models/{model_id}/rim_hparams.json\".split()\n",
    ")\n",
    "if args.json_override is not None:\n",
    "    if isinstance(args.json_override, list):\n",
    "        files = args.json_override\n",
    "    else:\n",
    "        files = [args.json_override,]\n",
    "    for file in files:\n",
    "        with open(file, \"r\") as f:\n",
    "            json_override = json.load(f)\n",
    "        args_dict = vars(args)\n",
    "        args_dict.update(json_override)\n",
    "cache_files = glob.glob(f\"{os.getenv('SLURM_TMPDIR')}/cache*\")\n",
    "for cache in cache_files:\n",
    "    os.remove(cache)\n",
    "rim, phys, train_dataset, val_dataset = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7baf97-1e6c-4243-b7a8-95f22634843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch, distributed_inputs in enumerate(train_dataset):\n",
    "    for res_idx in range(args.batch_size):\n",
    "        lens_true = distributed_inputs[0][res_idx]\n",
    "        lens_true /= tf.reduce_max(lens_true, axis=(0, 1, 2), keepdims=True)\n",
    "        source_true = distributed_inputs[1][res_idx]\n",
    "        kappa_true = distributed_inputs[2][res_idx]\n",
    "        source_pred, kappa_pred, chi_squared = rim.predict(lens_true[None])\n",
    "        lens_pred = phys.forward(source_pred[-1], kappa_pred[-1])[0]\n",
    "#         lam = tf.reduce_sum(lens_true * lens_pred) / tf.reduce_sum(lens_true**2)[..., tf.newaxis, tf.newaxis, tf.newaxis]\n",
    "        fig = residual_plot(lens_true, source_true, kappa_true, lens_pred, source_pred[-1][0, ...], kappa_pred[-1][0, ...], chi_squared[-1][0])\n",
    "        fig.suptitle(fr\"{batch}: Time step {args.steps+1}, $\\chi^2 = ${chi_squared[-1][0]:.2e}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8cc79-e348-470f-a066-6a81f4bbe225",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"RIMSU512_k128_NIE2nsvdO_007_TS10_F8_L4_IK7_NLrelu_al0.1_GAconcat_82_B10_lr0.0005_dr1.0_ds5000_TWquadratic_210923024919\"\n",
    "import sys\n",
    "sys.argv = ['']\n",
    "args = parser.parse_args(\n",
    "  f\"--model_id={os.getenv('CENSAI_PATH')}/models/{model_id} \"\\\n",
    "  f\"--datasets {os.getenv('CENSAI_PATH')}/data/lenses512_hk128_TNG100_10k_verydiffuse \"\\\n",
    "  f\"--compression_type=GZIP \"\\\n",
    "  f\"--forward_method=fft \"\\\n",
    "  f\"--optimizer=ADAM \"\\\n",
    "  f\"--epochs=200 \"\\\n",
    "  f\"--max_time=1 \"\\\n",
    "  f\"--initial_learning_rate=1e-3 \"\\\n",
    "  f\"--decay_rate=0.5 \"\\\n",
    "  f\"--decay_steps=100 \"\\\n",
    "  f\"--staircase \"\\\n",
    "  f\"--clipping \"\\\n",
    "  f\"--patience=20 \"\\\n",
    "  f\"--tolerance=0.01 \"\\\n",
    "  f\"--batch_size=10 \"\\\n",
    "  f\"--train_split=1 \"\\\n",
    "  f\"--total_items=1000 \"\\\n",
    "  f\"--block_length=1 \"\\\n",
    "  f\"--buffer_size=1000 \"\\\n",
    "#   f\"--steps=10 \"\\\n",
    "#   f\"--adam \"\\\n",
    "#   f\"--kappalog \"\\\n",
    "#   f\"--source_link=lrelu4p \"\\\n",
    "#   f\"--filters=16 \"\\\n",
    "#   f\"--filter_scaling=1.5 \"\\\n",
    "#   f\"--kernel_size=3 \"\\\n",
    "#   f\"--layers=5 \"\\\n",
    "#   f\"--block_conv_layers=2 \"\\\n",
    "#   f\"--resampling_kernel_size=3 \"\\\n",
    "#   f\"--gru_kernel_size=3 \"\\\n",
    "#   f\"--batch_norm \"\\\n",
    "#   f\"--dropout=0.1 \"\\\n",
    "#   f\"--upsampling_interpolation \"\\\n",
    "#   f\"--kernel_l2_amp=1e-4 \"\\\n",
    "#   f\"--bias_l2_amp=1e-4 \"\\\n",
    "#   f\"--kernel_l1_amp=1e-3 \"\\5e-3\n",
    "#   f\"--bias_l1_amp=1e-3 \"\\\n",
    "#   f\"--activation=leaky_relu \"\\\n",
    "#   f\"--alpha=0.3 \"\\\n",
    "  f\"--cache_file={os.getenv('SLURM_TMPDIR')}/cache \"\\\n",
    "  f\"--logdir={os.getenv('HOME')}/scratch/Censai/logs \"\\\n",
    "  f\"--logname=RIMSU512_k128_pretrained_hTNG \"\\\n",
    "  f\"--track_train \"\\\n",
    "  f\"--model_dir={os.getenv('HOME')}/scratch/Censai/models \"\\\n",
    "  f\"--checkpoints=5 \"\\\n",
    "  f\"--max_to_keep=3 \"\\\n",
    "  f\"--seed=42 \"\\\n",
    "  f\"--n_residuals=0 \"\\\n",
    "  f\"--json_override {os.getenv('CENSAI_PATH')}/models/{model_id}/unet_hparams.json {os.getenv('CENSAI_PATH')}/models/{model_id}/rim_hparams.json\".split()\n",
    "\n",
    ")\n",
    "if args.json_override is not None:\n",
    "    if isinstance(args.json_override, list):\n",
    "        files = args.json_override\n",
    "    else:\n",
    "        files = [args.json_override,]\n",
    "    for file in files:\n",
    "        with open(file, \"r\") as f:\n",
    "            json_override = json.load(f)\n",
    "        args_dict = vars(args)\n",
    "        args_dict.update(json_override)\n",
    "cache_files = glob.glob(f\"{os.getenv('SLURM_TMPDIR')}/cache*\")\n",
    "for cache in cache_files:\n",
    "    os.remove(cache)\n",
    "rim, phys, train_dataset, val_dataset = main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "censai",
   "language": "python",
   "name": "censai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
