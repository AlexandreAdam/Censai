{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "considered-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from censai import RIMUnet, PhysicalModel, RIM, RIMSharedUnet, PowerSpectrum\n",
    "from censai.models import VAE, VAESecondStage, SharedUnetModel, UnetModel\n",
    "from censai.utils import rim_residual_plot, update\n",
    "from censai.data.lenses_tng_v2 import decode_train, decode_physical_model_info\n",
    "from censai.definitions import log_10\n",
    "import os, glob, re, json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from argparse import Namespace\n",
    "import math, json\n",
    "import matplotlib.pylab as pylab\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 2000)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "result_dir = os.path.join(os.getenv(\"CENSAI_PATH\"), \"results\")\n",
    "data_path = os.path.join(os.getenv(\"CENSAI_PATH\"), \"data\")\n",
    "models_path = os.path.join(os.getenv(\"CENSAI_PATH\"), \"models\")\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "#           'figure.figsize': (10, 10),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "automotive-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"RIMSU128hst_control_012_TS15_F16_211020033949\"\n",
    "# model = \"RIMSU128hst_control_010_TS10_F16_211020033949\"\n",
    "# model = \"RIMSU128hst_control_009_TS8_F32_211020033949\"\n",
    "model = \"RIMSU128hst_control_007_TS6_F32_211020033237\"\n",
    "_dataset = \"lenses128hst_TNG_VAE_200k_control_validated_val\"\n",
    "\n",
    "checkpoints_dir = os.path.join(os.getenv(\"CENSAI_PATH\"), \"models\", model)\n",
    "\n",
    "with open(os.path.join(checkpoints_dir, \"script_params.json\"), \"r\") as f:\n",
    "    args = json.load(f)\n",
    "args = Namespace(**args)\n",
    "\n",
    "files = glob.glob(os.path.join(os.getenv(\"CENSAI_PATH\"), \"data\", _dataset, \"*.tfrecords\"))\n",
    "# Read concurrently from multiple records\n",
    "files = tf.data.Dataset.from_tensor_slices(files)\n",
    "dataset = files.interleave(lambda x: tf.data.TFRecordDataset(x, compression_type=\"GZIP\"),\n",
    "                           block_length=1, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Read off global parameters from first example in dataset\n",
    "for physical_params in dataset.map(decode_physical_model_info):\n",
    "    break\n",
    "dataset = dataset.map(decode_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "valued-vegetation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2b4410b53730>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "phys = PhysicalModel(\n",
    "    pixels=physical_params[\"pixels\"].numpy(),\n",
    "    kappa_pixels=physical_params[\"kappa pixels\"].numpy(),\n",
    "    src_pixels=physical_params[\"src pixels\"].numpy(),\n",
    "    image_fov=physical_params[\"image fov\"].numpy(),\n",
    "    kappa_fov=physical_params[\"kappa fov\"].numpy(),\n",
    "    src_fov=physical_params[\"source fov\"].numpy(),\n",
    "    method=args.forward_method,\n",
    "    noise_rms=physical_params[\"noise rms\"].numpy(),\n",
    "    psf_sigma=physical_params[\"psf sigma\"].numpy()\n",
    ")\n",
    "\n",
    "unet = SharedUnetModel(\n",
    "    filters=args.filters,\n",
    "    filter_scaling=args.filter_scaling,\n",
    "    kernel_size=args.kernel_size,\n",
    "    layers=args.layers,\n",
    "    block_conv_layers=args.block_conv_layers,\n",
    "    strides=args.strides,\n",
    "    bottleneck_kernel_size=args.bottleneck_kernel_size,\n",
    "    bottleneck_filters=args.bottleneck_filters,\n",
    "    resampling_kernel_size=args.resampling_kernel_size,\n",
    "    input_kernel_size=args.input_kernel_size,\n",
    "    gru_kernel_size=args.gru_kernel_size,\n",
    "    upsampling_interpolation=args.upsampling_interpolation,\n",
    "    kernel_l2_amp=args.kernel_l2_amp,\n",
    "    bias_l2_amp=args.bias_l2_amp,\n",
    "    kernel_l1_amp=args.kernel_l1_amp,\n",
    "    bias_l1_amp=args.bias_l1_amp,\n",
    "    activation=args.activation,\n",
    "    alpha=args.alpha,\n",
    "    initializer=args.initializer,\n",
    "    batch_norm=args.batch_norm,\n",
    "    dropout_rate=args.dropout_rate\n",
    ")\n",
    "rim = RIMSharedUnet(\n",
    "    physical_model=phys,\n",
    "    unet=unet,\n",
    "    steps=args.steps,\n",
    "    adam=args.adam,\n",
    "    kappalog=args.kappalog,\n",
    "    source_link=args.source_link,\n",
    "    kappa_normalize=args.kappa_normalize,\n",
    "    kappa_init=args.kappa_init,\n",
    "    source_init=args.source_init\n",
    ")\n",
    "ckpt = tf.train.Checkpoint(net=rim.unet)\n",
    "checkpoint_manager = tf.train.CheckpointManager(ckpt, checkpoints_dir, max_to_keep=args.max_to_keep)\n",
    "checkpoint_manager.checkpoint.restore(checkpoint_manager.latest_checkpoint).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "facial-encounter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [07:31<00:00, 90.33s/it]\n"
     ]
    }
   ],
   "source": [
    "k_bins = 40\n",
    "total_items = 5000\n",
    "examples_per_shard = 1000\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "output_dir = os.path.join(os.getenv(\"CENSAI_PATH\"), \"results\", model + \"_\" + _dataset)\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "ps_lens = PowerSpectrum(bins=k_bins, pixels=physical_params[\"pixels\"].numpy())\n",
    "ps_x = PowerSpectrum(bins=k_bins,  pixels=physical_params[\"kappa pixels\"].numpy())\n",
    "\n",
    "shards = total_items // examples_per_shard + 1 * (total_items % examples_per_shard > 0)\n",
    "k = 0\n",
    "for shard in tqdm(range(shards)):\n",
    "    hf = h5py.File(os.path.join(output_dir, f\"predictions_{shard:02d}.h5\"), 'w')\n",
    "    data = dataset.skip(shard * examples_per_shard).take(examples_per_shard).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    for batch, (lens, source, kappa) in enumerate(data):\n",
    "        source_pred, kappa_pred, chi_squared = rim.predict(lens)\n",
    "        lens_pred = phys.forward(source_pred[-1], kappa_pred[-1])\n",
    "        lam = phys.lagrange_multiplier(y_true=lens, y_pred=lens_pred)\n",
    "\n",
    "        # remove channel dimension because power spectrum expect only [batch, pixels, pixels] shaped tensor.\n",
    "        _ps_lens = ps_lens.cross_correlation_coefficient(lens[..., 0], lens_pred[..., 0])\n",
    "        _ps_kappa = ps_x.cross_correlation_coefficient(log_10(kappa)[..., 0], log_10(kappa_pred[-1])[..., 0])\n",
    "        _ps_source = ps_x.cross_correlation_coefficient(source[..., 0], source_pred[-1][..., 0])\n",
    "\n",
    "        batch_size = lens.shape[0]\n",
    "        for b in range(batch_size):\n",
    "            g = hf.create_group(f'data_{k:d}')\n",
    "            g.create_dataset(\"lens\",        data=lens[b])\n",
    "            g.create_dataset(\"source\",      data=source[b])\n",
    "            g.create_dataset(\"kappa\",       data=kappa[b])\n",
    "            g.create_dataset(\"lens_pred\",   data=lens_pred[b])\n",
    "            g.create_dataset(\"source_pred\", data=source_pred[:, b])\n",
    "            g.create_dataset(\"kappa_pred\",  data=kappa_pred[:, b])\n",
    "            g.create_dataset(\"chi_squared\", data=chi_squared[:, b])\n",
    "            g.create_dataset(\"lambda\",      data=lam[b])\n",
    "            g.create_dataset(\"ps_lens\",     data=_ps_lens[b])\n",
    "            g.create_dataset(\"ps_kappa\",    data=_ps_kappa[b])\n",
    "            g.create_dataset(\"ps_source\",   data=_ps_source[b])\n",
    "            k += 1\n",
    "    hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nasty-mailman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/aadam/scratch/Censai/results/RIMSU128hst_control_007_TS6_F32_211020033237_lenses128hst_TNG_VAE_200k_control_validated_val'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-freeware",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
