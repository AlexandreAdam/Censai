{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "victorian-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from censai import RIMUnet, PhysicalModel, RIM, RIMSharedUnet, PowerSpectrum\n",
    "from censai.models import VAE, VAESecondStage, SharedUnetModel, UnetModel\n",
    "from censai.utils import rim_residual_plot, update\n",
    "from censai.data.lenses_tng_v2 import decode_train, decode_physical_model_info\n",
    "from censai.definitions import log_10\n",
    "import os, glob, re, json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from argparse import Namespace\n",
    "import math, json\n",
    "import matplotlib.pylab as pylab\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 2000)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "result_dir = os.path.join(os.getenv(\"CENSAI_PATH\"), \"results\")\n",
    "data_path = os.path.join(os.getenv(\"CENSAI_PATH\"), \"data\")\n",
    "models_path = os.path.join(os.getenv(\"CENSAI_PATH\"), \"models\")\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "#           'figure.figsize': (10, 10),\n",
    "         'axes.labelsize': 'x-large',\n",
    "         'axes.titlesize':'x-large',\n",
    "         'xtick.labelsize':'x-large',\n",
    "         'ytick.labelsize':'x-large'}\n",
    "pylab.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "actual-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"RIMSU512_k128_NIEs_019_TI1000_32_B5_210918011431\"\n",
    "# model = \"RIMSU512_k128_NIEs_017_TI1000_16_B5_210918010833\"\n",
    "# model = \"RIMSU512_k128_NIE2nsvdO_033_TS10_F16_L5_IK11_NLrelu_al0.04_GAplus_42_B10_lr0.0005_dr0.8_ds5000_TWquadratic_210923032150\"\n",
    "# dataset = \"lenses512_k128_NIE_10k_verydiffuse\"\n",
    "model = \"RIMSU128hst_control_012_TS15_F16_211020033949\"\n",
    "_dataset = \"lenses128hst_TNG_VAE_200k_control_validated_val\"\n",
    "\n",
    "checkpoints_dir = os.path.join(os.getenv(\"CENSAI_PATH\"), \"models\", model)\n",
    "\n",
    "with open(os.path.join(checkpoints_dir, \"script_params.json\"), \"r\") as f:\n",
    "    args = json.load(f)\n",
    "args = Namespace(**args)\n",
    "\n",
    "files = glob.glob(os.path.join(os.getenv(\"CENSAI_PATH\"), \"data\", _dataset, \"*.tfrecords\"))\n",
    "# Read concurrently from multiple records\n",
    "files = tf.data.Dataset.from_tensor_slices(files)\n",
    "dataset = files.interleave(lambda x: tf.data.TFRecordDataset(x, compression_type=\"GZIP\"),\n",
    "                           block_length=1, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# Read off global parameters from first example in dataset\n",
    "for physical_params in dataset.map(decode_physical_model_info):\n",
    "    break\n",
    "dataset = dataset.map(decode_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accessory-species",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2b3859ac4040>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "phys = PhysicalModel(\n",
    "    pixels=physical_params[\"pixels\"].numpy(),\n",
    "    kappa_pixels=physical_params[\"kappa pixels\"].numpy(),\n",
    "    src_pixels=physical_params[\"src pixels\"].numpy(),\n",
    "    image_fov=physical_params[\"image fov\"].numpy(),\n",
    "    kappa_fov=physical_params[\"kappa fov\"].numpy(),\n",
    "    src_fov=physical_params[\"source fov\"].numpy(),\n",
    "    method=args.forward_method,\n",
    "    noise_rms=physical_params[\"noise rms\"].numpy(),\n",
    "    psf_sigma=physical_params[\"psf sigma\"].numpy()\n",
    ")\n",
    "\n",
    "unet = SharedUnetModel(\n",
    "    filters=args.filters,\n",
    "    filter_scaling=args.filter_scaling,\n",
    "    kernel_size=args.kernel_size,\n",
    "    layers=args.layers,\n",
    "    block_conv_layers=args.block_conv_layers,\n",
    "    strides=args.strides,\n",
    "    bottleneck_kernel_size=args.bottleneck_kernel_size,\n",
    "    bottleneck_filters=args.bottleneck_filters,\n",
    "    resampling_kernel_size=args.resampling_kernel_size,\n",
    "    input_kernel_size=args.input_kernel_size,\n",
    "    gru_kernel_size=args.gru_kernel_size,\n",
    "    upsampling_interpolation=args.upsampling_interpolation,\n",
    "    kernel_l2_amp=args.kernel_l2_amp,\n",
    "    bias_l2_amp=args.bias_l2_amp,\n",
    "    kernel_l1_amp=args.kernel_l1_amp,\n",
    "    bias_l1_amp=args.bias_l1_amp,\n",
    "    activation=args.activation,\n",
    "    alpha=args.alpha,\n",
    "    initializer=args.initializer,\n",
    "    batch_norm=args.batch_norm,\n",
    "    dropout_rate=args.dropout_rate\n",
    ")\n",
    "rim = RIMSharedUnet(\n",
    "    physical_model=phys,\n",
    "    unet=unet,\n",
    "    steps=args.steps,\n",
    "    adam=args.adam,\n",
    "    kappalog=args.kappalog,\n",
    "    source_link=args.source_link,\n",
    "    kappa_normalize=args.kappa_normalize,\n",
    "    kappa_init=args.kappa_init,\n",
    "    source_init=args.source_init\n",
    ")\n",
    "ckpt = tf.train.Checkpoint(net=rim.unet)\n",
    "checkpoint_manager = tf.train.CheckpointManager(ckpt, checkpoints_dir, max_to_keep=args.max_to_keep)\n",
    "checkpoint_manager.checkpoint.restore(checkpoint_manager.latest_checkpoint).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bda49c3-1027-4003-b6ef-bb59d654ba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:51<11:27, 171.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2b389fd54b20>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)  File \"<ipython-input-28-433ba2cef1a5>\", line 19, in <module>\n",
      "    source_pred, kappa_pred, chi_squared = rim.predict(lens)  File \"/lustre04/scratch/aadam/Censai/censai/rim_shared_unet.py\", line 196, in predict\n",
      "    source, kappa, states = self.time_step(source, kappa, source_grad, kappa_grad, states)  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/tensorflow/python/util/tf_should_use.py\", line 247, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2b389fd54b20>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)  File \"<ipython-input-28-433ba2cef1a5>\", line 19, in <module>\n",
      "    source_pred, kappa_pred, chi_squared = rim.predict(lens)  File \"/lustre04/scratch/aadam/Censai/censai/rim_shared_unet.py\", line 196, in predict\n",
      "    source, kappa, states = self.time_step(source, kappa, source_grad, kappa_grad, states)  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/tensorflow/python/util/tf_should_use.py\", line 247, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2b389fd54eb0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)  File \"<ipython-input-28-433ba2cef1a5>\", line 19, in <module>\n",
      "    source_pred, kappa_pred, chi_squared = rim.predict(lens)  File \"/lustre04/scratch/aadam/Censai/censai/rim_shared_unet.py\", line 196, in predict\n",
      "    source, kappa, states = self.time_step(source, kappa, source_grad, kappa_grad, states)  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/tensorflow/python/util/tf_should_use.py\", line 247, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2b389fd54eb0>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)  File \"<ipython-input-28-433ba2cef1a5>\", line 19, in <module>\n",
      "    source_pred, kappa_pred, chi_squared = rim.predict(lens)  File \"/lustre04/scratch/aadam/Censai/censai/rim_shared_unet.py\", line 196, in predict\n",
      "    source, kappa, states = self.time_step(source, kappa, source_grad, kappa_grad, states)  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/tensorflow/python/util/tf_should_use.py\", line 247, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2b3859c38c40>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)  File \"<ipython-input-28-433ba2cef1a5>\", line 19, in <module>\n",
      "    source_pred, kappa_pred, chi_squared = rim.predict(lens)  File \"/lustre04/scratch/aadam/Censai/censai/rim_shared_unet.py\", line 196, in predict\n",
      "    source, kappa, states = self.time_step(source, kappa, source_grad, kappa_grad, states)  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/tensorflow/python/util/tf_should_use.py\", line 247, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:==================================\n",
      "Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):\n",
      "<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x2b3859c38c40>\n",
      "If you want to mark it as used call its \"mark_used()\" method.\n",
      "It was originally created here:\n",
      "  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)  File \"<ipython-input-28-433ba2cef1a5>\", line 19, in <module>\n",
      "    source_pred, kappa_pred, chi_squared = rim.predict(lens)  File \"/lustre04/scratch/aadam/Censai/censai/rim_shared_unet.py\", line 196, in predict\n",
      "    source, kappa, states = self.time_step(source, kappa, source_grad, kappa_grad, states)  File \"/home/aadam/environments/censai3.8/lib/python3.8/site-packages/tensorflow/python/util/tf_should_use.py\", line 247, in wrapped\n",
      "    return _add_should_use_warning(fn(*args, **kwargs),\n",
      "==================================\n",
      "100%|██████████| 5/5 [14:20<00:00, 172.09s/it]\n"
     ]
    }
   ],
   "source": [
    "k_bins = 40\n",
    "total_items = 5000\n",
    "examples_per_shard = 1000\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "output_dir = os.path.join(os.getenv(\"CENSAI_PATH\"), \"results\", model + \"_\" + _dataset)\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "ps_lens = PowerSpectrum(bins=k_bins, pixels=physical_params[\"pixels\"].numpy())\n",
    "ps_x = PowerSpectrum(bins=k_bins,  pixels=physical_params[\"kappa pixels\"].numpy())\n",
    "\n",
    "shards = total_items // examples_per_shard + 1 * (total_items % examples_per_shard > 0)\n",
    "k = 0\n",
    "for shard in tqdm(range(shards)):\n",
    "    hf = h5py.File(os.path.join(output_dir, f\"predictions_{shard:02d}.h5\"), 'w')\n",
    "    data = dataset.skip(shard * examples_per_shard).take(examples_per_shard).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    for batch, (lens, source, kappa) in enumerate(data):\n",
    "        source_pred, kappa_pred, chi_squared = rim.predict(lens)\n",
    "        lens_pred = phys.forward(source_pred[-1], kappa_pred[-1])\n",
    "        lam = phys.lagrange_multiplier(y_true=lens, y_pred=lens_pred)\n",
    "\n",
    "        # remove channel dimension because power spectrum expect only [batch, pixels, pixels] shaped tensor.\n",
    "        _ps_lens = ps_lens.cross_correlation_coefficient(lens[..., 0], lens_pred[..., 0])\n",
    "        _ps_kappa = ps_x.cross_correlation_coefficient(log_10(kappa)[..., 0], log_10(kappa_pred[-1])[..., 0])\n",
    "        _ps_source = ps_x.cross_correlation_coefficient(source[..., 0], source_pred[-1][..., 0])\n",
    "\n",
    "        batch_size = lens.shape[0]\n",
    "        for b in range(batch_size):\n",
    "            g = hf.create_group(f'data_{k:d}')\n",
    "            g.create_dataset(\"lens\",        data=lens[b])\n",
    "            g.create_dataset(\"source\",      data=source[b])\n",
    "            g.create_dataset(\"kappa\",       data=kappa[b])\n",
    "            g.create_dataset(\"lens_pred\",   data=lens_pred[b])\n",
    "            g.create_dataset(\"source_pred\", data=source_pred[:, b])\n",
    "            g.create_dataset(\"kappa_pred\",  data=kappa_pred[:, b])\n",
    "            g.create_dataset(\"chi_squared\", data=chi_squared[:, b])\n",
    "            g.create_dataset(\"lambda\",      data=lam[b])\n",
    "            g.create_dataset(\"ps_lens\",     data=_ps_lens[b])\n",
    "            g.create_dataset(\"ps_kappa\",    data=_ps_kappa[b])\n",
    "            g.create_dataset(\"ps_source\",   data=_ps_source[b])\n",
    "            k += 1\n",
    "    hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9cf136-4ca5-4a36-80ac-9b3999217d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "censai",
   "language": "python",
   "name": "censai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
